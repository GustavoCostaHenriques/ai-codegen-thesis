%%
%% This is file `sample-sigchi.tex',
%% generated with the docstrip utility.
%% but modified by the faculty @ DI/FCUL
%% The original source files were:
%%
%% samples.dtx  (with options: `sigchi')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigchi.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\usepackage{subcaption}
\usepackage{caption}
\usepackage{array}
\usepackage{multirow}
\renewcommand{\abstractname}{Resumo}

%% end of the preamble, start of the body of the document source.
\begin{document}

\title{Construção de um Modelo de Desenvolvimento/Geração de Código com IA} 

\author{Gustavo Orlando Costa dos Santos Henriques - 64361}
\affiliation{%
 \institution{
  Estudo Orientado \\ 
  Mestrado em Engenharia Informática \\ 
  Faculdade de Ciências, Universidade de Lisboa}
 }
\email{fc64361@fc.ul.pt}


\begin{abstract}
%A Inteligência Artificial está a tornar-se cada vez mais comum no dia a dia da sociedade, atuando como um recursco para simplificar e automatizar certas tarefas, como o desenvolvimento de software. Com isto surgiram os Large Languages Models, que têm a capacidade de gerar vários tipos de output a partir de inputs variados. Contudo, estes modelos ainda enfrentem desafios como a coerência e fiabilidade. A presente tese tem como objetivo desenvolver um modelo capaz de gerar código a partir de descrições textuais e visuais, tendo como caso de uso a criação de uma wiki interna na Trust Systems, permitindo aos trabalhadores gerir as suas tarefas. Este trabalho irá avaliar como estratégias de prompt engineering serão capazes de influenciar a qualidade do código gerado, contribuindo para uma melhor compreensão da automatização do desenvolvimento de software com LLMs.
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\maketitle
\noindent\textit{\textbf{Palavras-chave}} \textit{Inteligência artificial; Grandes modelos de linguagem (LLMs); Engenharia de prompts; Geração automática de código; Engenharia de software}
\pagestyle{plain} % removes running headers

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\section{Introdução}

%%Context - What is the scientific/technological context of the topic of your project?
%Graças aos avanços da inteligência artificial nos últimos anos, a forma como é desenvolvido o software tem evoluído significativamente. Uma grande revolução que se deu em IA foi por volta de 2018, quando começaram a surgir os primeiros Large Language Models, como o BERT \cite{BERT} e o GPT-1\cite{GPT-1}, que se baseavam na arquitetura dos transformers, conceito este que foi introduzido em 2017\cite{Transformer}. Desde então estes modelos têm sofrido alterações no sentido de se tentar otimizar a sua performance, sendo hoje em dia capazes de gerar e completar código executável\cite{LLMSurvey}.\par
%Com estas contínuas melhorias, hoje existem ferramentas como o GitHub Copilot ou Amazon CodeWhisperer que conseguem auxiliar o trabalho de um programador, causando um impacto significativo na sua produtividade\cite{CopilotRole}.\\\par

%%Problem - What is the original problem your addressed in your project?
%Embora estes modelos e ferramentas, assistidos por IA, trazerem consigo beneficios para o ambiente empresarial, é importante referir que têm as suas limitações no que toca a segurança, qualidade, robustez e confiabilidade. Estudos feitos à robustez do GitHub Copilot indicam que, pequenas alterações de input podem originar alterações significativas no código gerado em, aproximadamente, 46\% dos casos\cite{CopilotStudy}. Além disso, Nam Huynh and Beiyu Lin\cite{LLMSurvey}, concluiram que 40\% do código gerado pelo Copilot continha vulnerabilidades na segurança. Com isto é possível concluir que mesmo com toda a automatização existente, continua a ser essencial uma análise humana que seja rigorosa e, que é vital o modo como construimos o input que será recebido pelos modelos. Com isto, surgiram técnicas mais recentes, designadas de prompt engineering, que estudam como o design dos prompts pode influenciar o desempenho dos LLMs e diminuir o impacto das limitações referidas.\\\par

%%Motivation - Why is this problem important and relevant? What justifies your project? How is your work on this problem different from what was already done (if something was done)? 
%Apesar dos avanços e de uma grande expectativa à volta do poder da IA, ainda há muitos domínios que permanecem num estado inicial, com incertezas quanto ao seu real potencial, como o prompt engineering e o desenvolvimento autónomo de software. Além disso, os algoritmos existentes, para avaliação de modelos, ainda não são suficientes para tratar de um modo sistemático e comparável as suas capacidades e os seus potenciais riscos\cite{MetricasSurvey}. Portanto, considerando o impacto que estas técnicas podem causar na redução de custos e na otimização de recursos, conclui-se que é importante a pesquisa dos limites dos LLMs visto que pode trazer consequências significativas para a sociedade atual.\par 

%%Goals -  What are the main goals of your project?
%Neste trabalho especificamente, a finalidade é estudar o estado da arte dos Large Language Models e das técnicas de prompt engineering no domínio da geração automática de código. O principal intento é analisar como estas abordagens podem ser implementadas de modo a produzir código, com a melhor qualidade disponível. Qualidade essa que será avaliada através de métricas automáticas e manuais, tentando assim identificar o potencial atual da IA para o desenvolvimento de software.

\noindent\textbf{Outline.} How is the rest of the document structured? \\The remainder of this document is organised as follows. Section \ref{sec:background} presents bla bla bla. ...

\section{Enquadramento Teórico} \label{sec:background}
Esta secção serve como base teórica para clarificar alguns conceitos importantes, oferecendo uma melhor compreensão das secções que se seguem.
%%In this section, you should describe the scientific or technological context of your project. Provide enough information so that a reader unfamiliar with the topic can understand the problem you are addressing and the rationale for your project. This may include relevant concepts and definitions in the area, particularly those that will be used throughout this document.
\subsection{Geração automática de código}


\subsection{Engenharia de prompts}
Para entedermos este conceito é primeiro necessário perceber a definição de prompt. Segundo Marvin et al.\cite{PEinLLMS} "A prompt is a text-based input that is fed to a language model to guide its output.
A prompt can be audio but, in this case, the audio input would be transcribed into text
and fed to the language model as a text-based prompt. The language model would then
process the text-based prompt and generate an output based on the instructions and
context provided in the prompt\dots", ou seja, um prompt é um input em formato textual (ou transcrição de outro meio, como áudio ou imagens) usado para orientar a saída de um modelo artificialmente inteligente, servindo para fornecer instruções e contexto, de modo a que o mesmo gere uma resposta em conformidade com a tarefa desejada.\\\par

Uma das influências na qualidade de resposta é a forma como são construídos estes prompts, visto que pequenas alterações nos mesmos são capazes de gerar respostas bastantes diferentes\cite{CopilotStudy}. Assim, por volta de 2022, emergiu esta nova disciplina no campo da inteligência artificial, que tem como objetivo conceber prompts e otimiza-los, tornando o uso de LLMs mais eficiente\cite{PEinLLMS}. Outra das razões para ter surgido o prompt engineering deve-se ao facto do custo de treinamento dos modelos. À medida que a complexidade dos modelos aumenta, os gastos em treinamento tornam-se cada vez maiores. Um estudo afirma que o custo associado aos modelos mais, computacionalmente intensivo, tem crescido a uma taxa de 2.4 vezes ao ano desde 2016\cite{LLMsTrainingCosts}. No entanto, ao usar estas técnicas, conseguimos afinar os LLMs sem gastar recursos para treinamento. Com isto, é notável a importância das mesmas visto que conseguem melhorar a qualidade do output sem necessitar de um dispendioso processo de treinamento.\\\par

Desde 2022 têm vindo a ser desenvolvidas várias estratégias de prompt engineering. Estas estratégias têm sempre um propósito específico que querem melhorar, desde a melhoria do raciocínio e lógica do modelo, até à redução de alucinações ou à geração e execução de código\cite{PETechniques}. Dependendo de cada estratégia utilizada, o prompt é construído de maneiras diferentes. No entanto, existem boas práticas gerais para a elaboração de prompts efetivos. De acordo com Marvin et al.\cite{PEinLLMS}, definir o objetivo, compreender as capacidades do modelo e fornecer contexto são alguns dos passos envolvidos na criação de um prompt eficaz.

%% Falar da estratégia que será usada neste caso específico

\section{Trabalho relacionado} \label{sec:relatedwork}

%%This section should present the state of the art on the topic of your project. It should discuss relevant related work and existing solutions, highlighting their main contributions as well as their limitations, and identifying the gaps or opportunities that motivate your project.

%%Preparing this section will require you to include references to academic papers, books, and possibly online resources. The next paragraph exemplifies how to do it.

%%\medskip

%%In this work, you are expected to follow the guidelines on document preparation presented in Lamport’s book on \LaTeX~\cite{lamport1994latex}. For editing, you may use tools such as the online platform Overleaf~\cite{overleaf}. There is also a good chance that your project will build upon some of Lamport’s many scientific contributions, such as the concept of logical clocks~\cite{lamport1978clocks}.
A presente secção reúne o estado da arte relevante para esta tese, apresentando trabalhos, modelos e ferramentas que abordam problemas relacionados com a aplicação de métodos de inteligência artificial ao desenvolvimento de software, a utilização de técnicas de prompting e avaliação de modelos.
\subsection{Geração Automática de Código}
Nesta secção são analisados trabalhos que ilustram várias abordagens para automatizar a transformação de descrições diretamente em código.\\\par

Xu et al.\cite{UItoCode} propõem um sistema que converte imagens de interfaces web em código HTML e CSS. O método assenta numa pipeline composta por três etapas principais: geração de um dataset com imagens e respetivo código, deteção dos componentes visuais da interface recorrendo a modelos como CNN\footnote{\href{https://cs231n.github.io/convolutional-networks/}{https://cs231n.github.io/convolutional-networks/}} e Faster R-CNN\footnote{\href{https://medium.com/@RobuRishabh/understanding-and-implementing-faster-r-cnn-248f7b25ff96}{https://medium.com/@RobuRishabh/understanding-and-implementing-faster-r-cnn-248f7b25ff96}} e, produção do código através de uma arquitetura que combina uma CNN para extração visual com uma LSTM\footnote{\href{https://colah.github.io/posts/2015-08-Understanding-LSTMs/}{https://colah.github.io/posts/2015-08-Understanding-LSTMs/}} responsável por gerar a sequência de código. Este trabalho é relevante para a presente dissertação por demonstrar uma abordagem para a transformação do design em estruturas front-end executáveis, alinhando-se com a componente da pipeline dedicada à geração automática da interface.\par

Hoje em dia já existem vários modelos generativos com a finalidade de desenvolvimento de código, ou seja, modelos que foram construídos com o objetivo principal de gerar como resposta um excerto de código que cumpre os requisitos solicitados pelo ser humano. Codex\cite{Codex} foi um dos primeiros modelos amplamente conhecidos para transformar descrições textuais em código executável, suportando múltiplas linguagens e tarefas como geração de funções, completamento e tradução entre linguagens. Este modelo serviu ainda de base ao GitHub Copilot, que será abordado mais adiante, estabelecendo um marco na utilização prática de LLMs para auxiliar o desenvolvimento de software.\par

Dando seguimento a esta ideia de ter modelos especilizados na geração de código, surgiu também o CodeLlama\cite{CodeLlama}, uma família de modelos orientados para tarefas de programação como geração, explicação e preenchimento de código. Estes modelos, que foram desenvolvidos com base no modelo Llama2\cite{Llama2}, são disponibilizados em três variantes distintas:\par
\textbf{Code Llama}, a versão base, implementada para tarefas mais gerais de compreensão e transformação de código;\par
\textbf{Code Llama - Python}, uma versão treinada adicionalmente com grandes bases de dados de código python, fornencendo um auxílio com mais qualidade em requisitos para esta linguagem;\par
\textbf{Code Llama - Instruct}, uma variante ajustada para seguir melhor as instruções humanas, oferecendo uma interação conversacional mais aprimorada.\par
Treinados para processar sintaxe estruturada e múltiplos paradigmas de programação, os modelos CodeLlama representam uma alternativa moderna e de acesso aberto (open-source), ideal para cenários que exigem a conversão de requisitos em linguagem natural diretamente para código.\par

Além disso, temos também o StarCoder\cite{StarCoder} e a sua evolução mais recente, StarCoder2\cite{StarCoder2}, que representam modelos treinados em larga escala no dataset The Stack (The Stack v2 para o modelo StarCoder2), destacando-se pelo suporte multilinguagem, capacidades de preenchimento, janelas de contexto alargadas, permitindo, com este último ponto, analisar blocos mais extensos de código numa única passagem, e mecanismos de treino orientados para segurança e transparência. Graças a estas características, tornam-se referências úteis para compreender boas práticas na construção de LLMs orientados para código, tanto ao nível da arquitetura e dos datasets, como das técnicas necessárias para desenvolver sistemas capazes de converter descrições em código de forma fiável e coerente.\\\par

Para além dos modelos dedicados à geração completa de código, têm surgido ferramentas práticas de assistência ao programador integradas diretamente nas IDEs. Um exemplo marcante é o GitHub Copilot\footnote{\href{https://github.com/features/copilot}{https://github.com/features/copilot}}Baseado no modelo Codex, o Copilot funciona como um sistema de autocompletar código capaz de sugerir linhas ou blocos curtos com base no contexto imediato do ficheiro em edição. Ziegler et al.\cite{GitHubCopilot} estuda empiricamente a ferramenta analisando o comportamento da mesma e o seu impacto no processo de desenvolvimento, evidenciando como a completação incremental pode acelerar tarefas de rotina e reduzir o esforço cognitivo do programador.\par

De forma semelhante, a Amazon apresentou o CodeWhisperer\footnote{\href{https://aws.amazon.com/pt/q/developer/}{https://aws.amazon.com/pt/q/developer/}}, analisado no respetivo estudo técnico\cite{AmazonCodeWhisperer}, um assistente de programação concebido para gerar sugestões de código contextualizadas em múltiplas linguagens. Este trabalho compara o CodeWhisperer com outras ferramentas, incluindo o Copilot e o ChatGPT, avaliando a qualidade, correção e segurança das sugestões produzidas. Tal como o Copilot, o CodeWhisperer opera principalmente como um mecanismo de completação inteligente dentro da IDE, contribuindo para automatizar partes do fluxo de escrita de código e acelerar tarefas repetitivas.\par

Estas ferramentas demonstram que, para além de abordagens orientadas à geração integral de componentes de software, existe já uma adoção consolidada de LLMs em cenários de code completion no desenvolvimento real.

%% TODO - Falar sobre SDD

\section{«Other Section(s) as Appropriate»} \label{sec:work1}

The report should include one or more sections providing a detailed description of the problem you are addressing in the project and your plan to tackle it. Use appropriate section titles for what is presented. 

You should explain the methods you are planning to use, or have already started to apply, in your project. 
%
This discussion should be grounded in the related work, your own understanding of the problem, and, when available, preliminary results.

In case you already have some preliminary results, consider to include a section devoted to them. This section should  describe the work already carried out, what data has already been collected, what analysis and designs have already been done, what methods have been used, what programs and/or preliminary results already exist, etc.

\section{Forthcoming Work and Conclusions} \label{sec:conclusions}

This section should include subsections describing the work to be carried out during the remainder of the school year and its objectives. 
%
It should also present a chronological plan for the completion of the project. 
%
Finally, include a concluding subsection that summarizes the contributions already made, provides a preliminary self-assessment of the progress achieved so far, and discusses the main difficulties encountered.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

\end{document}
