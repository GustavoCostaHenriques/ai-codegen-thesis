%%
%% This is file `sample-sigchi.tex',
%% generated with the docstrip utility.
%% but modified by the faculty @ DI/FCUL
%% The original source files were:
%%
%% samples.dtx  (with options: `sigchi')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigchi.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{array}
\usepackage{multirow}
\usepackage{placeins}
\usepackage[portuguese]{babel}
\renewcommand{\figurename}{Figura}
\renewcommand{\abstractname}{Resumo}
\makeatletter
\def\fps@figure{htbp}
\makeatother

%% end of the preamble, start of the body of the document source.
\begin{document}

\title{Construção de um Modelo de Desenvolvimento/Geração de Código com IA} 

\author{Gustavo Orlando Costa dos Santos Henriques - 64361}
\affiliation{%
 \institution{
  Estudo Orientado \\ 
  Mestrado em Engenharia Informática \\ 
  Faculdade de Ciências, Universidade de Lisboa}
 }
\email{fc64361@fc.ul.pt}


\begin{abstract}
%A Inteligência Artificial está a tornar-se cada vez mais comum no dia a dia da sociedade, atuando como um recursco para simplificar e automatizar certas tarefas, como o desenvolvimento de software. Com isto surgiram os Large Languages Models, que têm a capacidade de gerar vários tipos de output a partir de inputs variados. Contudo, estes modelos ainda enfrentem desafios como a coerência e fiabilidade. A presente tese tem como objetivo desenvolver um modelo capaz de gerar código a partir de descrições textuais e visuais, tendo como caso de uso a criação de uma wiki interna na Trust Systems, permitindo aos trabalhadores gerir as suas tarefas. Este trabalho irá avaliar como estratégias de prompt engineering serão capazes de influenciar a qualidade do código gerado, contribuindo para uma melhor compreensão da automatização do desenvolvimento de software com LLMs.
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\maketitle
\noindent\textit{\textbf{Palavras-chave}} \textit{Inteligência artificial; Grandes modelos de linguagem (LLMs); Engenharia de prompts; Geração automática de código; Engenharia de software}
\pagestyle{plain} % removes running headers

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\section{Introdução}

%%Context - What is the scientific/technological context of the topic of your project?
%Graças aos avanços da inteligência artificial nos últimos anos, a forma como é desenvolvido o software tem evoluído significativamente. Uma grande revolução que se deu em IA foi por volta de 2018, quando começaram a surgir os primeiros Large Language Models, como o BERT \cite{BERT} e o GPT-1\cite{GPT-1}, que se baseavam na arquitetura dos transformers, conceito este que foi introduzido em 2017\cite{Transformer}. Desde então estes modelos têm sofrido alterações no sentido de se tentar otimizar a sua performance, sendo hoje em dia capazes de gerar e completar código executável\cite{LLMSurvey}.\par
%Com estas contínuas melhorias, hoje existem ferramentas como o GitHub Copilot ou Amazon CodeWhisperer que conseguem auxiliar o trabalho de um programador, causando um impacto significativo na sua produtividade\cite{CopilotRole}.\\\par

%%Problem - What is the original problem your addressed in your project?
%Embora estes modelos e ferramentas, assistidos por IA, trazerem consigo beneficios para o ambiente empresarial, é importante referir que têm as suas limitações no que toca a segurança, qualidade, robustez e confiabilidade. Estudos feitos à robustez do GitHub Copilot indicam que, pequenas alterações de input podem originar alterações significativas no código gerado em, aproximadamente, 46\% dos casos\cite{CopilotStudy}. Além disso, Nam Huynh and Beiyu Lin\cite{LLMSurvey}, concluiram que 40\% do código gerado pelo Copilot continha vulnerabilidades na segurança. Com isto é possível concluir que mesmo com toda a automatização existente, continua a ser essencial uma análise humana que seja rigorosa e, que é vital o modo como construimos o input que será recebido pelos modelos. Com isto, surgiram técnicas mais recentes, designadas de prompt engineering, que estudam como o design dos prompts pode influenciar o desempenho dos LLMs e diminuir o impacto das limitações referidas.\\\par

%%Motivation - Why is this problem important and relevant? What justifies your project? How is your work on this problem different from what was already done (if something was done)? 
%Apesar dos avanços e de uma grande expectativa à volta do poder da IA, ainda há muitos domínios que permanecem num estado inicial, com incertezas quanto ao seu real potencial, como o prompt engineering e o desenvolvimento autónomo de software. Além disso, os algoritmos existentes, para avaliação de modelos, ainda não são suficientes para tratar de um modo sistemático e comparável as suas capacidades e os seus potenciais riscos\cite{MetricasSurvey}. Portanto, considerando o impacto que estas técnicas podem causar na redução de custos e na otimização de recursos, conclui-se que é importante a pesquisa dos limites dos LLMs visto que pode trazer consequências significativas para a sociedade atual.\par 

%%Goals -  What are the main goals of your project?
%Neste trabalho especificamente, a finalidade é estudar o estado da arte dos Large Language Models e das técnicas de prompt engineering no domínio da geração automática de código. O principal intento é analisar como estas abordagens podem ser implementadas de modo a produzir código, com a melhor qualidade disponível. Qualidade essa que será avaliada através de métricas automáticas e manuais, tentando assim identificar o potencial atual da IA para o desenvolvimento de software.

\noindent\textbf{Outline.} How is the rest of the document structured? \\The remainder of this document is organised as follows. Section \ref{sec:background} presents bla bla bla. ...

\section{Enquadramento Teórico} \label{sec:background}
Esta secção serve como base teórica para clarificar alguns conceitos importantes, oferecendo uma melhor compreensão das secções que se seguem.
%%In this section, you should describe the scientific or technological context of your project. Provide enough information so that a reader unfamiliar with the topic can understand the problem you are addressing and the rationale for your project. This may include relevant concepts and definitions in the area, particularly those that will be used throughout this document.
\subsection{Geração automática de código}
A geração automática de código consiste no processo de produzir componentes de software de forma parcial ou integral a partir de descrições de mais alto nível, como requisitos em linguagem natural, esquemas visuais, modelos formais ou exemplos estruturados. Em vez de o programador escrever manualmente o código fonte, recorrem-se a sistemas capazes de interpretar estas descrições e traduzir o seu conteúdo para implementações concretas, acelerando o desenvolvimento e reduzindo tarefas repetitivas.\par
Apesar da geração automática de código estar hoje em dia associada a modelos de inteligência artificial, o conceito não é própriamente recente. Já existiam abordagens como o Model-Driven Engineering (MDE), onde o código era gerado a partir de modelos formais, como por exemplo diagramas ou estruturas abstratas que descreviam o sistema e, linguagens específicas de domínio (DSLs), que permitiam escrever descrições declarativas que depois eram traduzidas automaticamente para código. Contudo, estas técnicas dependiam de regras de transformação rígidas e gramáticas estritamente definidas, o que as tornava eficazes apenas em domínios muito controlados e pouco adaptáveis a requisitos mais abertos ou expressos em linguagem natural.\\\par

\indent\textbf{Modelos de Linguagem}\par
Os modelos de linguagem surgiram como uma evolução significativa na geração automática de código ao permitirem interpretar instruções menos estruturadas, como texto em linguagem natural. Estes modelos são treinados em grandes volumes de dados, incluindo código fonte, documentação e exemplos de uso, o que lhes permite aprender padrões sintáticos, estruturas típicas de implementação e relações entre diferentes elementos de um programa.\par
Uma parte importante desta evolução deve-se à arquitetura Transformer, introduzida em 2017 por Vaswani et al.\cite{Transformer}, que se tornou a base dos modelos de linguagem modernos. Os Transformers utilizam mecanismos de atenção para identificar, dentro de uma sequência de texto, quais são as partes mais relevantes para cada palavra, permitindo compreender relações complexas e dependências a longo alcance. Esta arquitetura revelou-se altamente eficiente para tarefas de processamento de linguagem natural e tornou possível treinar modelos de grande escala capazes de compreender e gerar código com elevada coerência.\par
Ao longo desta evolução têm surgido cada vez mais sistemas que exploram o potencial dos modelos de linguagem para apoiar ou automatizar partes do processo de desenvolvimento de software. Alguns destes sistemas recorrem a um único modelo para interpretar descrições e gerar código de forma direta, enquanto outros combinam vários modelos ou etapas especializadas para orientar, validar ou complementar a geração. Esta diversidade reflete a maturidade crescente da área e o interesse em integrar modelos de linguagem não só como geradores de código, mas também como assistentes ativos no fluxo de trabalho do programador. Exemplos representativos destas abordagens são discutidos de forma detalhada na secção \ref{CODE_GENERATION_TR}.\\\par

\indent\textbf{Desafios e Limitações}\par
TODO

\subsection{Engenharia de Prompts} \label{PE-BACKGROUND}
Para entendermos este conceito, é primeiro necessário perceber a definição de prompt. Segundo Marvin et al.\cite{PEinLLMS}, um prompt é um input em formato textual (ou transcrição de outro meio, como áudio ou imagens) usado para orientar a saída de um modelo artificialmente inteligente, servindo para fornecer instruções e contexto, de modo a que o mesmo gere uma resposta em conformidade com a tarefa desejada.\\\par

Uma das influências na qualidade de resposta é a forma como são construídos estes prompts, visto que pequenas alterações nos mesmos são capazes de gerar respostas bastante diferentes\cite{CopilotStudy}. Assim, por volta de 2022, emergiu esta nova disciplina no campo da inteligência artificial chamada prompt engineering, que tem como objetivo conceber prompts e otimizá-los, tornando o uso de LLMs mais eficiente\cite{PEinLLMS}. Outra das razões para ter surgido o prompt engineering deve-se ao facto do custo de treino dos modelos. À medida que a complexidade dos modelos aumenta, os gastos em treino tornam-se cada vez maiores. Cottier et al.\cite{CostIncreaseInLLMS} estudo afirma que o custo associado aos modelos computacionalmente mais intensivos, tem crescido a uma taxa de 2.4 vezes ao ano desde 2016. Assim, ao recorrer à disciplina de engenharia de prompts, conseguimos afinar os LLMs sem gastar recursos para treinamento. Com isto, é notável a importância das mesmas, visto que conseguem melhorar a qualidade do output sem necessitar de um dispendioso processo de treino.\\\par

Desde 2022 têm vindo a ser desenvolvidas várias estratégias de prompt engineering. Estas estratégias têm sempre um propósito específico que querem melhorar, desde a melhoria do raciocínio e lógica do modelo, até à redução de alucinações\cite{PETechniques}. Dependendo de cada estratégia utilizada, o prompt é construído de maneiras diferentes. No entanto, de acordo com Marvin et al.\cite{PEinLLMS} existem boas práticas gerais para a elaboração de prompts efetivos, como definir o objetivo, compreender as capacidades do modelo e fornecer contexto.

%% Falar da estratégia que será usada neste caso específico

\section{Trabalho relacionado} \label{sec:relatedwork}

%%This section should present the state of the art on the topic of your project. It should discuss relevant related work and existing solutions, highlighting their main contributions as well as their limitations, and identifying the gaps or opportunities that motivate your project.

%%Preparing this section will require you to include references to academic papers, books, and possibly online resources. The next paragraph exemplifies how to do it.

%%\medskip

%%In this work, you are expected to follow the guidelines on document preparation presented in Lamport’s book on \LaTeX~\cite{lamport1994latex}. For editing, you may use tools such as the online platform Overleaf~\cite{overleaf}. There is also a good chance that your project will build upon some of Lamport’s many scientific contributions, such as the concept of logical clocks~\cite{lamport1978clocks}.
A presente secção reúne o estado da arte relevante para esta tese, apresentando trabalhos, modelos e ferramentas que abordam problemas relacionados com a aplicação de métodos de inteligência artificial ao desenvolvimento de software, a utilização de técnicas de prompting e avaliação de modelos.
\subsection{Geração Automática de Código} \label{CODE_GENERATION_TR}
Nesta secção são analisados trabalhos que ilustram várias abordagens para automatizar a transformação de descrições diretamente em código.\\\par

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.85\textwidth]{../../img/codellama_family.png}
    \caption{Pipeline de especialização do Code Llama\cite{CodeLlama}.}
    \label{fig:codellama-pipeline}
\end{figure*}

Hoje em dia já existem vários modelos generativos com a finalidade de desenvolvimento de código, ou seja, modelos que foram construídos com o objetivo principal de gerar como resposta um excerto de código que cumpre os requisitos solicitados pelo ser humano. Codex\cite{Codex} foi um dos primeiros modelos amplamente conhecidos para transformar descrições textuais em código executável, suportando múltiplas linguagens e tarefas como geração de funções, completamento e tradução entre linguagens. Este modelo serviu ainda de base ao GitHub Copilot, que será abordado mais adiante, estabelecendo um marco na utilização prática de LLMs para auxiliar o desenvolvimento de software.\par

Dando seguimento a esta ideia, surgiu o CodeLlama\cite{CodeLlama}, uma família de modelos orientados para tarefas de programação como geração, explicação e preenchimento de código. Estes modelos, que foram desenvolvidos com base no modelo Llama2\cite{Llama2}, são disponibilizados em três variantes distintas especificadas abaixo e na figura\ref{fig:codellama-pipeline}:\par
\textbf{Code Llama}, a versão base, implementada para tarefas mais gerais de compreensão e transformação de código;\par
\textbf{Code Llama - Python}, uma versão treinada adicionalmente com grandes bases de dados de código python, fornecendo um auxílio com mais qualidade em requisitos para esta linguagem em específico;\par
\textbf{Code Llama - Instruct}, uma variante ajustada para seguir melhor as instruções humanas, oferecendo uma interação conversacional mais aprimorada.\par
Treinados para processar sintaxe estruturada e múltiplos paradigmas de programação, os modelos CodeLlama representam uma alternativa moderna e de acesso aberto (open-source), ideal para cenários que exigem a conversão de requisitos em linguagem natural diretamente para código.\par

Adicionalmente, temos também o StarCoder\cite{StarCoder} e a sua evolução mais recente, StarCoder2\cite{StarCoder2}, que representam modelos treinados em larga escala no dataset The Stack (The Stack v2 para o modelo StarCoder2), destacando-se pelo suporte multilinguagem, capacidades de preenchimento, janelas de contexto alargadas, permitindo, com este último ponto, analisar blocos mais extensos de código numa única passagem, e mecanismos de treino orientados para segurança e transparência. Graças a estas características, tornam-se referências úteis para compreender boas práticas na construção de LLMs orientados para código, tanto ao nível da arquitetura e dos datasets, como das técnicas necessárias para desenvolver sistemas capazes de converter descrições em código de forma fiável e coerente.\\\par

Para além dos modelos dedicados à geração de código, têm surgido ferramentas práticas de assistência ao programador integradas diretamente nas IDEs (ambientes de desenvolvimento integrado). Um exemplo marcante é o GitHub Copilot\footnote{\href{https://github.com/features/copilot}{https://github.com/features/copilot}}, inicialmente alimentado pelo modelo Codex, uma variante do GPT-3 especializada em código. Com a evolução da ferramenta, o Copilot passou também a incorporar modelos mais avançados, como o GPT-4 e GPT-4o. Hoje em dia já inclui modos autónomos como o modo de agente e o agente de programação, capazes de executar ações dentro da IDE ou desenvolver tarefas completas de forma assistida. Ziegler et al.\cite{GitHubCopilot} estudaram empiricamente a ferramenta analisando o comportamento da mesma e o seu impacto no processo de desenvolvimento, evidenciando como a completamento incremental pode acelerar tarefas de rotina e reduzir o esforço cognitivo do programador.\par

De forma semelhante, a Amazon apresentou o CodeWhisperer\footnote{\href{https://aws.amazon.com/pt/q/developer/}{https://aws.amazon.com/pt/q/developer/}}, um assistente de programação concebido para gerar sugestões de código contextualizadas em múltiplas linguagens. Yetistiren et al.\cite{AmazonCodeWhisperer} compararam o CodeWhisperer com outras ferramentas, incluindo o Copilot e o ChatGPT, avaliando a qualidade, correção e segurança das sugestões produzidas. Tal como o Copilot, o CodeWhisperer opera principalmente como um mecanismo de completamento inteligente dentro da IDE, contribuindo para automatizar partes do fluxo de escrita de código e acelerar tarefas repetitivas.\par

Estas ferramentas demonstram que, para além de abordagens orientadas à geração integral de componentes de software, existe já uma adoção consolidada de LLMs em cenários de completamento de código no desenvolvimento real.\\\par

Nos últimos tempos, surgiram também ferramentas que vão de encontro ao conceito de Spec-Driven Development (SDD), onde, em vez de se implementar o código primeiro e documentá-lo posteriormente, começa-se por definir as especificações que irão servir de guia para os agentes de IA. Entre estas destaca-se o Spec-Kit\footnote{\href{https://github.com/github/spec-kit}{https://github.com/github/spec-kit}}, desenvolvido pela equipa de IA do GitHub, uma ferramenta que fornece uma interface de linha de comandos para criar e organizar especificações, planos e tarefas capazes de guiar modelos generativos ao longo de um fluxo de desenvolvimento. De forma complementar, o Kiro\footnote{\href{https://kiro.dev}{https://kiro.dev}}, desenvolvido pela Kiro Labs, apresenta-se como um ambiente integrado que combina edição de especificações com agentes capazes de gerar e atualizar código com base nesses ficheiros estruturados. Embora ainda recentes, ambas as ferramentas ilustram uma nova tendência no desenvolvimento de software onde se criam fluxos automáticos que partem de especificações formais para produzir componentes coerentes.\par

Além destas ferramentas, existe já investigação académica que explora abordagens semelhantes. Patil et al.\cite{Spec2Code} apresentam o spec2code, um framework que combina modelos de linguagem com verificadores formais para gerar código C a partir de especificações estruturadas. Existe também investigação centrada na geração automática das próprias especificações formais. Um exemplo recente é o SpecGen, proposto por Ma et al.\cite{SpecGen}, que utiliza modelos de linguagem para produzir contratos formais, a partir de código-fonte ou descrições textuais. O sistema gera especificações em linguagens como JML\cite{JML} e avalia a sua consistência e verificabilidade utilizando verificadores formais. O SpecGen demonstra o papel crescente dos LLMs na automatização de etapas tradicionalmente manuais.\\\par

Para além das abordagens baseadas em especificações, surgem também trabalhos que seguem caminhos distintos na geração automática de código. Embora não se integrem no mesmo enquadramento teórico, constituem contribuições relevantes por explorarem problemas mais específicos, como a transformação de interfaces visuais em estruturas front-end. Xu et al.\cite{UItoCode} propõem um sistema que converte imagens de interfaces web em código HTML e CSS. O método assenta num fluxo composto por três etapas principais: geração de um dataset com imagens e respetivo código, deteção dos componentes visuais da interface recorrendo a modelos como CNN\cite{CNN} e Faster R-CNN\cite{R-CNN} e, produção do código através de uma arquitetura que combina uma CNN para extração visual com uma LSTM\cite{LSTM} responsável por gerar a sequência de código. Este trabalho demonstra uma abordagem interessante para a transformação do design em estruturas front-end executáveis, alinhando-se com a componente da tese dedicada à geração automática de código para a interface.\\\par

A figura\ref{fig:timeline-modelos} ilustra a progressão dos sistemas analisados, apresentando uma linha temporal que sintetiza o seu aparecimento. Contudo, há que ter em conta que atualmente existe um ecossistema muito vasto de ferramentas e modelos generativos orientados a programação que vai muito para além do que foi mencionado nesta secção. A sua evolução tem sido contínua e acelerada, com contribuições de várias organizações como OpenAI, Meta, Google, AWS e a comunidade de código aberto.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.4\textheight, width=0.3\textwidth]{../../img/code_generation_tineline.png}
    \caption{Linha temporal dos modelos e ferramentas de geração de código analisados nesta secção.}
    \label{fig:timeline-modelos}
\end{figure}

\subsection{Engenharia de Prompts}
Como já foi referido na secção \ref{PE-BACKGROUND}, a forma como as instruções são fornecidas a um modelo de linguagem tem um impacto direto na qualidade do código que o mesmo consegue gerar. Diversos trabalhos mostram que técnicas de engenharia de prompts podem melhorar significativamente o desempenho em tarefas de linguagem natural para código. Esta secção apresenta estudos que aplicam estas técnicas em cenários reais de geração de código, evidenciando a sua importância prática no desenvolvimento de sistemas baseados em LLMs.\\\par

Um dos estudos no contexto da engenharia de prompts aplicada à geração de código é o trabalho de Liu et al.\cite{ChatGPTGenerationPE}, que investiga a forma como diferentes estratégias de prompting influenciam o desempenho do ChatGPT em tarefas de geração de código . Os autores avaliam o modelo no benchmark CodeXGlue e demonstram que a formulação do prompt tem um impacto substancial na qualidade do código gerado. O estudo aplica técnicas como chain-of-thought, instruções comportamentais e otimizações multi-etapa, mostrando, através de métricas como o BLEU e CodeBLEU, que o desempenho do ChatGPT pode melhorar significativamente.\par

Adicionalmente Wang et al.\cite{PET-SELECT}, afirmam que, apesar dos avanços recentes nos LLMs, continua a ser difícil garantir que estes produzam código correto e robusto de forma consistente. Para mitigar este problema, os autores propõem o PET-Select, um método que seleciona automaticamente a técnica de prompting mais adequada com base na complexidade do problema. Avaliado em benchmarks como MBPP e HumanEval, o PET-Select mostrou melhorias moderadas na qualidade do código e reduções significativas no custo de geração, demonstrando que a escolha informada da estratégia de prompting pode ter impacto real no desempenho de modelos orientados à programação.\par

Um outro contributo é apresentado por Khojah et al.\cite{PEIMPACTWITHCODEPROMPTEVAL}, que exploraram o impacto de diferentes técnicas de prompt engineering na geração de código. Os autores introduzem o CodePromptEval, um dataset composto por 7072 prompts concebido para avaliar cinco técnicas distintas (few-shot, persona, chain-of-thought, function signature e list of packages) aplicadas à geração de funções completas em 3 modelos, o GPT-4o, Llama 3 e Mistral. O estudo mostra que algumas destas técnicas influenciam de forma significativa a correção e qualidade do código produzido. Contudo, a combinação de várias técnicas não garante necessariamente melhorias adicionais.

Para além das técnicas de prompting aplicadas diretamente ao enunciado da tarefa, existe uma linha de investigação que explora estratégias de closed-loop prompting, onde o modelo é instruído a analisar e refinar o próprio código após a primeira geração. Ding et al.\cite{PECYCLE} apresentam o CYCLE, um método que combina geração inicial com iterações sucessivas de auto-refinamento orientadas por feedback, mostrando melhorias na qualidade final do código. De forma complementar, Zhou et al.\cite{PEREFINERCODE} propõem o RefineCoder, que incorpora um mecanismo adaptativo de crítica e correção para permitir que o LLM identifique e ajuste erros no código que produz. Ambos os trabalhos reforçam que a melhoria iterativa guiada pelo próprio modelo pode ser uma alternativa eficaz às abordagens que dependem exclusivamente do prompt inicial, contribuindo para aumentar a fiabilidade do código gerado.

\section{«Other Section(s) as Appropriate»} \label{sec:work1}

The report should include one or more sections providing a detailed description of the problem you are addressing in the project and your plan to tackle it. Use appropriate section titles for what is presented. 

You should explain the methods you are planning to use, or have already started to apply, in your project. 
%
This discussion should be grounded in the related work, your own understanding of the problem, and, when available, preliminary results.

In case you already have some preliminary results, consider to include a section devoted to them. This section should  describe the work already carried out, what data has already been collected, what analysis and designs have already been done, what methods have been used, what programs and/or preliminary results already exist, etc.

\section{Forthcoming Work and Conclusions} \label{sec:conclusions}

This section should include subsections describing the work to be carried out during the remainder of the school year and its objectives. 
%
It should also present a chronological plan for the completion of the project. 
%
Finally, include a concluding subsection that summarizes the contributions already made, provides a preliminary self-assessment of the progress achieved so far, and discusses the main difficulties encountered.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

\end{document}
