%%
%% This is file `sample-sigchi.tex',
%% generated with the docstrip utility.
%% but modified by the faculty @ DI/FCUL
%% The original source files were:
%%
%% samples.dtx  (with options: `sigchi')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigchi.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{array}
\usepackage{multirow}
\usepackage{placeins}
\usepackage[table]{xcolor}
\usepackage{tabularx}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta}
\definecolor{headergray}{RGB}{220, 230, 236} % Azul acinzentado muito suave
\definecolor{ganttblue}{RGB}{110, 155, 180}

\usepackage[portuguese]{babel}
\renewcommand{\figurename}{Figura}
\renewcommand{\abstractname}{Resumo}
\makeatletter
\def\fps@figure{htbp}
\makeatother


%% end of the preamble, start of the body of the document source.
\begin{document}

\title{Construção de um Modelo de Geração de Código com IA} 

\author{Gustavo Orlando Costa dos Santos Henriques - 64361}
\affiliation{%
 \institution{
  Estudo Orientado \\ 
  Mestrado em Engenharia Informática \\ 
  Faculdade de Ciências, Universidade de Lisboa}
 }
\email{fc64361@alunos.fc.ul.pt}


\begin{abstract}
Os avanços recentes na inteligência artificial generativa têm permitido automatizar partes do desenvolvimento de software. No entanto, a adoção destas tecnologias em contextos empresariais exige a sua adaptação de práticas internas e aos fluxos de trabalho já estabelecidos. Este documento descreve o projeto a desenvolver na Trust Systems, que tem como objetivo analisar, selecionar e combinar modelos de linguagem de grande escala (LLMs), para construir uma \textit{pipeline} que automatize etapas relevantes do processo de desenvolvimento de software da empresa. A abordagem vai basear-se na utilização de LLMs existentes e em técnicas de \textit{prompt engineering} para assegurar a qualidade e coerência dos artefactos gerados.\\\par
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\noindent\textit{\textbf{Palavras-chave}} \textit{Inteligência Artificial Generativa; Modelos de linguagem de grande escala (LLMs); Engenharia de prompts; Geração automática de código; Engenharia de software}
\end{abstract}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
\pagestyle{plain} % removes running headers
\section{Introdução}

%%Context - What is the scientific/technological context of the topic of your project?
\noindent{A} inteligência artificial generativa tem vindo a transformar várias etapas do processo de desenvolvimento de software, permitindo automatizar tarefas que tradicionalmente exigiam significativa intervenção humana\cite{LLM4SE}. Modelos de linguagem de grande escala tornaram-se capazes de interpretar instruções e gerar código a partir dessas descrições\cite{Codex}, bem como produzir explicações, documentação e outros artefactos associados ao ciclo de vida do software\cite{GPT4Experiments}.\\\par

%%Problem - What is the original problem your addressed in your project?
\noindent{Apesar} do sucesso destas tecnologias, o desafio é conseguir adaptá-las de forma eficaz ao processo concreto de desenvolvimento utilizado em contextos empresariais. O projeto descrito neste documento foca-se no problema de conseguir aplicar, adaptar e combinar tecnologias de inteligência artificial generativa, de forma a automatizar etapas do processo de desenvolvimento de software da Trust Systems, incluindo a interpretação inicial de requisitos, a geração de propostas de interfaces, a definição de especificações de API e a produção de código de backend e frontend a partir dessas especificações, garantindo alinhamento com os seus métodos e constrangimentos operacionais.\\\\\par

\noindent\textbf{Motivação}

\noindent{A} automatização de partes do desenvolvimento de software permite reduzir o esforço associado a tarefas simples e repetitivas, acelerando o processo de desenvolvimento\cite{CopilotStudy}. Ao libertar os programadores destas atividades, torna-se possível dedicar mais tempo em problemas de maior complexidade e valor, o que contribui para uma utilização mais eficiente das competências da equipa e para a melhoria global do processo de desenvolvimento em contexto empresarial. No contexto da Trust Systems, torna-se particularmente relevante compreender como integrar modelos de linguagem de grande escala no processo de desenvolvimento já existente, uma vez que as soluções disponíveis são concebidas de forma genérica e não refletem a sequência de fases específica do processo adotado internamente. Deste modo, este projeto irá contribuir para a adoção responsável e eficiente de modelos de linguagem de grande escala no ambiente real da empresa.
\\\par

\noindent\textbf{Objetivo}

\noindent{O} objetivo geral do projeto é desenvolver e avaliar uma \textit{pipeline} modular que utilize tecnologias de inteligência artificial generativa, nomeadamente modelos de linguagem, para automatizar etapas relevantes do processo de desenvolvimento de software da Trust Systems. Para tal, o projeto visa, por um lado, analisar e selecionar modelos e tecnologias existentes que se revelem adequados ao contexto organizacional e, por outro, definir e implementar uma \textit{pipeline} baseada na utilização desses modelos de forma iterativa e controlada, recorrendo a técnicas de \textit{prompt engineering} como mecanismo de especialização e controlo do seu comportamento. A abordagem proposta para este projeto assume a existência de pontos de validação humana ao longo do processo, nos quais os artefactos gerados são revistos, ajustados e validados antes de servirem de base para as fases seguintes, garantindo a qualidade e a conformidade das soluções produzidas.\\\par

\noindent\textbf{Organização do Documento} 

\noindent{O} presente documento encontra-se organizado da seguinte forma. A secção \ref{sec:background} apresenta o enquadramento teórico necessário à contextualização do trabalho, abordando conceitos relacionados como a geração automática de código, o ciclo de vida do desenvolvimento de software e técnicas de controlo e refinamento do comportamento dos modelos. A secção \ref{sec:relatedwork} analisa o trabalho relacionado, incluindo modelos, ferramentas e abordagens existentes para a geração de código e engenharia de \textit{prompts}. Na secção \ref{sec:processo_trust} é descrito o processo de desenvolvimento de software atualmente adotado na Trust Systems, detalhando cada uma das fases principais. O Capítulo \ref{sec:proposta} apresenta a \textit{pipeline} proposta, explicando a sua arquitetura modular, os diferentes componentes envolvidos e os mecanismos de validação e refinamento dos artefactos gerados. Por fim, a secção \ref{sec:planeamento} descreve o planeamento do trabalho, incluindo as fases de implementação, avaliação e documentação do projeto.   

\section{Enquadramento Teórico} \label{sec:background}

Esta secção serve como base teórica para clarificar alguns conceitos importantes para o projeto, permitindo uma melhor compreensão das secções que se seguem.\\\par

%%In this section, you should describe the scientific or technological context of your project. Provide enough information so that a reader unfamiliar with the topic can understand the problem you are addressing and the rationale for your project. This may include relevant concepts and definitions in the area, particularly those that will be used throughout this document.

\noindent\textbf{Geração automática de código}\par
\noindent{A} geração automática de código consiste no processo de produzir código fonte a partir de descrições de alto nível, como requisitos em linguagem natural, esquemas visuais, modelos formais ou exemplos estruturados. Em vez de o programador escrever manualmente o código fonte, recorre-se a sistemas capazes de interpretar estas descrições e traduzir o seu conteúdo para implementações concretas, acelerando o desenvolvimento e reduzindo tarefas repetitivas.\par

\medskip\noindent{Apesar} da geração automática de código estar hoje em dia associada à inteligência artificial generativa, a ideia não é nova. A geração de código foi explorada em abordagens como o Model-Driven Engineering (MDE), onde o código é produzido a partir de modelos formais, como diagramas ou estruturas abstratas\cite{MDE-Schmidt,MDEInPratice}, e em linguagens específicas de domínio (DSLs), que estão equipadas com tradutoress de descrições declarativas para código\cite{DSLs}. Contudo, estas técnicas baseiam-se em regras rígidas e gramáticas estritamente definidas, sendo eficazes sobretudo em domínios controlados e pouco flexíveis perante requisitos abertos ou em linguagem natural.\\\par

\noindent{Os} modelos de IA generativa, disponibilizados amplamente a partir de 2022, marcaram uma evolução na geração automática de código ao permitirem interpretar instruções pouco estruturadas em linguagem natural\cite{Codex}. Esta capacidade resulta do treino em grandes volumes de dados heterogéneos, incluindo código fonte, documentação e exemplos de implementação, que expõem simultaneamente linguagem natural e linguagens de programação, permitindo aprender padrões sintáticos e relações entre componentes de um programa.\\

\noindent{Uma} parte importante desta evolução deve-se à arquitetura \textit{Transformer}, proposta em 2017 por Vaswani et al.\cite{Transformer}. Os \textit{Transformers} utilizam mecanismos de atenção que relacionam tokens distantes numa sequência, capturando dependências de longo alcance e identificando as partes mais relevantes da instrução, o que se revelou altamente eficiente para tarefas de linguagem natural e permitiu treinar modelos de grande escala capazes de gerar código coerente\cite{Codex}.\\

%%\begin{figure}[htbp]
  %%  \centering
  %%  \includegraphics[height=0.4\textheight, width=0.3\textwidth]{../../img/transformer.png}
  %%  \caption{Arquitetura Transformer proposta por Vaswani et al.\cite{Transformer}}
  %%  \label{fig:transformer}
%%\end{figure}

\noindent{Ao} longo dos últimos três anos têm surgido cada vez mais sistemas que exploram o potencial dos modelos de linguagem para apoiar ou automatizar partes do processo de desenvolvimento de software. Alguns destes sistemas recorrem a um único modelo para interpretar descrições e gerar código de forma direta, enquanto outros combinam vários modelos ou etapas especializadas para orientar, validar ou complementar a geração. Esta diversidade reflete a maturidade crescente da área e o interesse em integrar modelos de linguagem não só como geradores de código, mas também como assistentes ativos no fluxo de trabalho do programador. Exemplos representativos destas abordagens são discutidos de forma detalhada na secção \ref{CODE_GENERATION_TR}.\\\par

\noindent\textbf{Ciclo de Vida do Desenvolvimento de Software}\par

\noindent{Embora} os avanços nas LLMs demonstrem o seu potencial para a geração de código, a construção de um produto de software envolve um conjunto mais amplo de fases, cuja natureza, ordem e grau de formalização podem variar significativamente consoante o tipo de sistema e o contexto organizacional. Para contextualizar o impacto e o papel que a automatização pode assumir, é necessário compreender o ciclo de vida completo do desenvolvimento de software\cite{ALLLIFECYCLE}, identificando as etapas onde é possível introduzir automatização. \\\par

\noindent{Estas} etapas incluem, em primeiro lugar, a elicitação e análise de requisitos, que visam garantir que as necessidades do cliente sejam adequadamente compreendidas, estruturadas e documentadas. O processo de elicitação de requisitos envolve diversas técnicas, incluindo entrevistas e revisões literárias, como evidenciado por Lim et al.\cite{RE}, que destacam a importância de métodos eficazes para alcançar uma compreensão abrangente das necessidades dos utilizadores, uma vez que os requisitos devidamente capturados constituem a base sobre a qual todo o ciclo de vida do software é construído.\par

\noindent{Com} os requisitos definidos, a modelação funcional e estrutural do sistema surge como etapa subsequente, frequentemente suportada por linguagens formais e semi-formais de representação como a UML (Unified Modeling Language), BPMN (Business Process Model and Notation) para processos de negócio ou SysML (Systems Modeling Language) para sistemas complexos. Estas linguagens permitem traduzir requisitos textuais em representações visuais, facilitando a análise, validação e comunicação entre equipas técnicas e não técnicas. Os modelos UML desempenham um papel crítico na documentação e validação de requisitos, servindo como elementos centrais de coordenação entre diferentes perspetivas do sistema\cite{UML}. Esta modelação inclui diagramas de casos de uso, classes, atividades ou sequência, que complementam a descrição funcional do sistema e ajudam a desenhar o comportamento desejado. Neste contexto, a conceção de interfaces e fluxos de interação emerge como um artefacto fundamental, permitindo validar o comportamento esperado do sistema do ponto de vista do utilizador e servindo de base para decisões técnicas subsequentes, nomeadamente ao nível da definição de APIs e da implementação.\par

\noindent{A} definição de APIs (Application Programming Interfaces) e dos componentes arquiteturais constitui outra etapa fundamental, pois estabelece os contratos de comunicação entre as diferentes partes do sistema. Especificações claras de APIs permitem uma implementação mais consistente, facilitam a integração entre módulos e suportam estratégias de teste orientadas a componentes e serviços.

\noindent{Depois} da definição dos componentes e das interfaces do sistema, segue-se a fase de implementação, onde o código é desenvolvido de acordo com as especificações definidas. Esta etapa envolve não apenas a programação propriamente dita, mas também a integração de módulos e a resolução de dependências técnicas, garantindo que os componentes funcionem de forma coesa. A implementação é acompanhada por atividades de verificação e validação, onde se aplicam diferentes níveis de testes, com o objetivo de identificar defeitos, avaliar comportamentos e assegurar que o software cumpre os requisitos estabelecidos. Por fim, a documentação técnica desempenha um papel transversal a todas estas fases, registando decisões, especificações, arquiteturas, APIs e procedimentos de utilização, facilitando a manutenção futura e promovendo uma compreensão consistente do sistema entre programadores e \textit{stakeholders}.\\\par

\noindent{Para} além das etapas que compõem o desenvolvimento de software, importa considerar também as metodologias que organizam estas atividades ao longo do ciclo de vida. Os processos tradicionais, como o modelo em cascata (Waterfall)\cite{Waterfall}, estruturavam o desenvolvimento de forma sequencial, com transições rígidas entre etapas. Com o tempo, esta abordagem revelou limitações em cenários de requisitos dinâmicos, particularmente em contextos de mudança frequente ou incerteza elevada, conduzindo à adoção de metodologias ágeis, que promovem ciclos iterativos, entregas incrementais e adaptação contínua às necessidades do utilizador\cite{Agile}, como ilustrado na Figura \ref{fig:waterfall_agile}.\\\par

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.2\textheight, width=0.45\textwidth]{../../img/waterfall_agille.png}
    \caption{Comparação entre os modelos Waterfall e modelos Iterativos}
    \label{fig:waterfall_agile}
\end{figure}

\noindent\textbf{Limitações dos LLMs e Técnicas de Refinamento} \label {PE-BACKGROUND}

\noindent{Apesar} dos avanços significativos alcançados pelos modelos de linguagem de grande escala, estes sistemas apresentam limitações que afetam diretamente a sua aplicação no desenvolvimento de software. Entre os desafios mais comuns encontram-se a geração de código incorreto ou incompleto, inconsistências lógicas, alucinações factuais e dificuldades em interpretar requisitos ambíguos ou instruções pouco estruturadas. Estas limitações resultam, em grande parte, da natureza estatística dos modelos, da variabilidade dos dados de treino e da ausência de mecanismos internos de verificação semântica.\par

\noindent{Para} mitigar estas limitações, diversas técnicas de refinamento têm sido exploradas. Uma abordagem consiste no treino adicional (\textit{fine-tuning}) sobre dados específicos de um domínio, com o objetivo de ajustar o comportamento do modelo às necessidades de uma organização ou tarefa concreta. No entanto, esta estratégia tem em geral custos elevados, sobretudo quando envolve retreinar modelos de larga escala, uma vez que requer recursos computacionais significativos. Cottier et al.\cite{Cottier} corroboram esta observação ao demonstrar que os custos computacionais associados ao treino e re-treino de modelos de linguagem têm crescido de forma acentuada, registando um aumento médio de 2.4 vezes por ano desde 2016.\\\par


\noindent{Neste} contexto, a engenharia de prompts (\textit{prompt engineering}) tornou-se uma alternativa particularmente relevante, fornecendo técnicas que procuram otimizar as instruções fornecidas ao modelo, estruturando-as de modo a orientar o comportamento do LLM sem necessidade de treino adicional. Estudos recentes têm demonstrado que a forma como o prompt é construído influencia significativamente a qualidade do código gerado, a clareza das explicações e a capacidade de o modelo seguir passos complexos\cite{CopilotStudy}. Ao estabelecer padrões, estratégias e boas práticas de formulação de prompts\cite{PEinLLMS}, é possível alcançar resultados mais fiáveis e reduzir ambiguidades inerentes à interpretação do modelo. Para além destas boas práticas gerais, a literatura identifica ainda um conjunto variado de técnicas específicas, cada uma concebida para atingir objetivos distintos, desde a melhoria do raciocínio e lógica do modelo, até à redução de alucinações, conforme sistematizado por Sahoo et al.\cite{PETechniques}.\par

\noindent{Dado} que esta dissertação visa explorar a automatização de diferentes etapas do desenvolvimento de software, a engenharia de prompts assume um papel central enquanto mecanismo de controlo e refinamento do comportamento dos modelos utilizados. O baixo custo operacional e a ausência de necessidade de treino especializado tornam esta abordagem particularmente adequada ao contexto estudado, permitindo adaptar modelos generalistas às tarefas específicas que compõem a pipeline de geração de software.\par

\section{Trabalho relacionado} \label{sec:relatedwork}

A presente secção reúne o estado da arte relevante para esta tese, apresentando trabalhos, modelos e ferramentas que abordam problemas relacionados com a aplicação de métodos de inteligência artificial ao desenvolvimento de software e a utilização de técnicas de prompting.\\\par

%%This section should present the state of the art on the topic of your project. It should discuss relevant related work and existing solutions, highlighting their main contributions as well as their limitations, and identifying the gaps or opportunities that motivate your project.

%%Preparing this section will require you to include references to academic papers, books, and possibly online resources. The next paragraph exemplifies how to do it.

%%\medskip

%%In this work, you are expected to follow the guidelines on document preparation presented in Lamport’s book on \LaTeX~\cite{lamport1994latex}. For editing, you may use tools such as the online platform Overleaf~\cite{overleaf}. There is also a good chance that your project will build upon some of Lamport’s many scientific contributions, such as the concept of logical clocks~\cite{lamport1978clocks}.

\noindent\textbf{Geração Automática de Código} \label{CODE_GENERATION_TR}

\noindent{Nesta} secção são analisados trabalhos que ilustram várias abordagens para automatizar a transformação de descrições diretamente em código.\\\par

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.85\textwidth]{../../img/codellama_family.pdf}
    \caption{Pipeline de especialização do Code Llama\cite{CodeLlama}.}
    \label{fig:codellama-pipeline}
\end{figure*}

\noindent{Hoje} em dia já existem vários modelos generativos com a finalidade de desenvolvimento de código, ou seja, modelos que foram construídos com o objetivo principal de gerar como resposta um excerto de código que cumpre os requisitos solicitados pelo ser humano. Codex\cite{Codex}, uma variante do GPT-3\cite{GPT-3} especializada em código, foi um dos primeiros modelos amplamente conhecidos para transformar descrições textuais em código executável, suportando múltiplas linguagens e tarefas como geração de funções, completamento e tradução entre linguagens. Este modelo serviu ainda de base ao GitHub Copilot (que será abordado mais adiante), estabelecendo um marco na utilização prática de LLMs para auxiliar o desenvolvimento de software.\par

\noindent{Dando} seguimento a esta ideia, surgiu o CodeLlama\cite{CodeLlama}, uma família de modelos orientados para tarefas de programação como geração, explicação e preenchimento de código. Estes modelos, que foram desenvolvidos com base no modelo Llama2\cite{Llama2}, são disponibilizados em três variantes distintas especificadas abaixo e na Figura \ref{fig:codellama-pipeline}:

\begin{itemize}
    \item \textbf{Code Llama}, a versão base, implementada para tarefas mais gerais de compreensão e transformação de código;
    \item \textbf{Code Llama - Python}, uma versão treinada adicionalmente com grandes bases de dados de código python, fornecendo um auxílio com mais qualidade em requisitos para esta linguagem em específico;
    \item \textbf{Code Llama - Instruct}, uma variante ajustada para seguir melhor as instruções humanas, oferecendo uma interação conversacional mais aprimorada.
\end{itemize}
\noindent{Treinados} para processar sintaxe estruturada e múltiplos paradigmas de programação, os modelos CodeLlama representam uma alternativa moderna e de acesso aberto (\textit{open-source}), ideal para cenários que exigem a conversão de requisitos em linguagem natural diretamente para código.\par

\noindent{Adicionalmente}, temos também o StarCoder\cite{StarCoder} e a sua evolução mais recente, StarCoder2\cite{StarCoder2}, que representam modelos treinados em larga escala no dataset The Stack (The Stack v2 para o modelo StarCoder2), destacando-se pelo suporte multilinguagem, capacidades de preenchimento, janelas de contexto alargadas, permitindo, com este último ponto, analisar blocos mais extensos de código numa única passagem, e mecanismos de treino orientados para segurança e transparência. Graças a estas características, tornam-se referências úteis para compreender boas práticas na construção de LLMs orientados para código, tanto ao nível da arquitetura e dos datasets, como das técnicas necessárias para desenvolver sistemas capazes de converter descrições em código de forma fiável e coerente.\\\par

\noindent{Para} além dos modelos dedicados à geração de código, têm surgido ferramentas práticas de assistência ao programador integradas diretamente nas IDEs (ambientes de desenvolvimento integrado). Um exemplo marcante é o GitHub Copilot\footnote{\href{https://github.com/features/copilot}{https://github.com/features/copilot}}, inicialmente alimentado pelo modelo Codex. Com a evolução da ferramenta, o Copilot passou também a incorporar modelos mais avançados, como o GPT-4 e GPT-4o. Hoje em dia já inclui modos autónomos como o modo de agente e o agente de programação, capazes de executar ações dentro da IDE ou desenvolver tarefas completas de forma assistida. Ziegler et al.\cite{GitHubCopilot} estudaram empiricamente a ferramenta analisando o comportamento da mesma e o seu impacto no processo de desenvolvimento, evidenciando como a completamento incremental pode acelerar tarefas de rotina e reduzir o esforço cognitivo do programador.\par

\noindent{De} forma semelhante, a Amazon apresentou o CodeWhisperer\footnote{\href{https://aws.amazon.com/pt/q/developer/}{https://aws.amazon.com/pt/q/developer/}}, um assistente de programação concebido para gerar sugestões de código contextualizadas em múltiplas linguagens. Yetistiren et al.\cite{AmazonCodeWhisperer} compararam o CodeWhisperer com outras ferramentas, incluindo o Copilot e o ChatGPT, avaliando a qualidade, correção e segurança das sugestões produzidas. Tal como o Copilot, o CodeWhisperer opera principalmente como um mecanismo de completamento inteligente dentro da IDE, contribuindo para automatizar partes do fluxo de escrita de código e acelerar tarefas repetitivas.\par

\noindent{A} crescente integração destas ferramentas diretamente nas IDEs mostra que os LLMs estão a ser efetivamente adotados no desenvolvimento de software no dia-a-dia, sobretudo em cenários de completamento de código. Esta adoção prática tem contribuído para acelerar tarefas rotineiras e aumentar a produtividade dos programadores\cite{CopilotRole}.\\

\noindent{Recentemente}, surgiram também ferramentas que suportam \textit{Spec-Driven Development} (SDD). A ideia chave do SDD é, em vez de se implementar o código primeiro e documentá-lo posteriormente, começa-se por definir as especificações que irão servir de guia para os agentes de IA. Estas especificações assumem-se como a fonte central de orientação do processo, podendo incluir listas de requisitos, componentes, tarefas e decisões tecnológicas que, em abordagens tradicionais, estariam distribuídas por diversos artefactos de análise e planeamento. Assim, uma parte significativa das atividades que antecedem a implementação é formalizada diretamente nestes ficheiros. Entre as ferramentas que suportam o SDD destaca-se o Spec-Kit\footnote{\href{https://github.com/github/spec-kit}{https://github.com/github/spec-kit}}, desenvolvido pela equipa de IA do GitHub, uma ferramenta que fornece uma interface de linha de comandos para criar e organizar especificações, planos e tarefas capazes de guiar modelos generativos ao longo de um fluxo de desenvolvimento. De forma complementar, o Kiro\footnote{\href{https://kiro.dev}{https://kiro.dev}}, desenvolvido pela Kiro Labs, apresenta-se como um ambiente integrado que combina edição de especificações com agentes capazes de gerar e atualizar código com base nesses ficheiros estruturados. Embora ainda recentes, ambas as ferramentas ilustram uma nova tendência no desenvolvimento de software onde se criam fluxos automáticos que partem de especificações estruturadas para produzir componentes coerentes.\par

\noindent{Além} destas ferramentas, têm surgido também propostas que abordam este problema recorrendo a especificações formais. Patil et al.\cite{Spec2Code} apresentam o spec2code, um framework que combina modelos de linguagem com verificadores formais para gerar código C a partir de especificações estruturadas. Existe também investigação centrada na geração automática das próprias especificações formais. Um exemplo recente é o SpecGen, proposto por Ma et al.\cite{SpecGen}, que utiliza modelos de linguagem para produzir contratos formais, a partir de código-fonte ou descrições textuais. O sistema gera especificações em linguagens como JML\cite{JML} e avalia a sua consistência e verificabilidade utilizando verificadores formais. O SpecGen demonstra o papel crescente dos LLMs na automatização de etapas tradicionalmente manuais.\\\par

%%\noindent{Para} além das abordagens baseadas em especificações, surgem também trabalhos que seguem caminhos distintos na geração automática de código. Embora não se integrem no mesmo enquadramento teórico, constituem contribuições relevantes por explorarem problemas mais específicos, como a transformação de interfaces visuais em estruturas front-end. Xu et al.\cite{UItoCode} propõem um sistema que converte imagens de interfaces web em código HTML e CSS. O método assenta num fluxo composto por três etapas principais: geração de um dataset com imagens e respetivo código, deteção dos componentes visuais da interface recorrendo a modelos como CNN\cite{CNN} e Faster R-CNN\cite{R-CNN} e, produção do código através de uma arquitetura que combina uma CNN para extração visual com uma LSTM\cite{LSTM} responsável por gerar a sequência de código. Este trabalho demonstra uma abordagem interessante para a transformação do design em estruturas front-end executáveis, alinhando-se com a componente da tese dedicada à geração automática de código para a interface.\\\par

\noindent{A} Figura \ref{fig:timeline-modelos} ilustra a cronologia dos sistemas analisados, apresentando uma linha temporal que sintetiza o seu aparecimento. Contudo, há que ter em conta que atualmente existe um ecossistema muito vasto de ferramentas e modelos generativos orientadas a programação que vai muito para além do que foi mencionado nesta secção. A sua evolução tem sido contínua e acelerada, com contribuições de várias organizações como OpenAI, Meta, Google, AWS e a comunidade de código aberto.\\

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.3\textheight, width=0.2\textwidth]{../../img/code_generation_tineline.png}
    \caption{Linha temporal dos modelos e ferramentas de geração de código analisados nesta secção.}
    \label{fig:timeline-modelos}
\end{figure}

\noindent\textbf{Engenharia de Prompts}

\noindent{Como} já foi referido na secção \ref{PE-BACKGROUND}, a forma como as instruções são fornecidas a um modelo de linguagem tem um impacto direto na qualidade do código que o mesmo consegue gerar. Diversos trabalhos mostram que técnicas de engenharia de prompts podem melhorar significativamente o desempenho em tarefas de linguagem natural para código \cite{ChatGPTGenerationPE,PEIMPACTWITHCODEPROMPTEVAL,PECYCLE}. No resto da secção, são apresentados estudos que aplicam estas técnicas em cenários reais de geração de código, evidenciando a sua importância prática no desenvolvimento de sistemas baseados em LLMs.\\\par


\noindent{Um} dos estudos no contexto da engenharia de prompts aplicada à geração de código é o trabalho de Liu et al.\cite{ChatGPTGenerationPE}, que investiga a forma como diferentes estratégias de prompting influenciam o desempenho do ChatGPT em tarefas de geração de código. Os autores avaliam o modelo no benchmark CodeXGlue, um conjunto de tarefas padronizadas para programação que inclui geração, tradução, refatoração e completamento de código, e demonstram que a formulação do prompt tem um impacto substancial na qualidade do código gerado. O estudo aplica técnicas como \textit{chain-of-thought}, instruções comportamentais e otimizações multi-etapa, mostrando que o desempenho do ChatGPT pode melhorar significativamente. Esta conclusão foi alcançada através de métricas como o BLEU que avalia a semelhança entre o código gerado e a solução de referência através da contagem de n-gramas, isto é, sequências contíguas de n tokens que permitem medir a sobreposição entre as duas versões de código e o CodeBLEU, que amplia a abordagem anterior ao incluir informação específica de programas, analisando não apenas n-gramas mas também a estrutura sintática representada por árvores AST e as relações de fluxo de dados.\\\par

\noindent{Adicionalmente} Wang et al.\cite{PET-SELECT}, afirmam que, apesar dos avanços recentes nos LLMs, continua a ser difícil garantir que estes produzam código correto e robusto de forma consistente. Para mitigar este problema, os autores propõem o PET-Select, um método que seleciona automaticamente a técnica de prompting mais adequada com base na complexidade do problema. Avaliado em benchmarks como MBPP e HumanEval, o PET-Select mostrou melhorias moderadas na qualidade do código e reduções significativas no custo de geração, demonstrando que a escolha informada da estratégia de prompting pode ter impacto real no desempenho de modelos orientados à programação.\\\par

\noindent{Um} outro contributo é apresentado por Khojah et al.\cite{PEIMPACTWITHCODEPROMPTEVAL}, que exploraram o impacto de diferentes técnicas de prompt engineering na geração de código. Os autores introduzem o CodePromptEval, um dataset composto por 7072 prompts concebido para avaliar cinco técnicas distintas (few-shot, persona, chain-of-thought, function signature e list of packages) aplicadas à geração de funções completas em 3 modelos, o GPT-4o, Llama 3 e Mistral. O estudo mostra que algumas destas técnicas influenciam de forma significativa a correção e qualidade do código produzido. Contudo, a combinação de várias técnicas não garante necessariamente melhorias adicionais.\\

\noindent{Para} além das técnicas de prompting aplicadas diretamente ao enunciado da tarefa, existe uma linha de investigação que explora estratégias de closed-loop prompting, onde o modelo é instruído a analisar e refinar o próprio código após a primeira geração. Ding et al.\cite{PECYCLE} apresentam o CYCLE, um método que combina geração inicial com iterações sucessivas de auto-refinamento orientadas por feedback, mostrando melhorias na qualidade final do código. De forma complementar, Zhou et al.\cite{PEREFINERCODE} propõem o RefineCoder, que incorpora um mecanismo adaptativo de crítica e correção para permitir que o LLM identifique e ajuste erros no código que produz. Ambos os trabalhos reforçam que a melhoria iterativa guiada pelo próprio modelo pode ser uma alternativa eficaz às abordagens que dependem exclusivamente do prompt inicial, contribuindo para aumentar a fiabilidade do código gerado.

\section{Processo de Desenvolvimento de Software da Trust Systems} \label{sec:processo_trust}

Esta secção descreve o processo de desenvolvimento de produtos adotado pela Trust Systems, apresentando as principais etapas que estruturam a construção de uma solução desde a sua conceção inicial até à sua validação final. O objetivo é caracterizar o fluxo interno seguido pela empresa, evidenciando a forma como as equipas analisam o mercado, definem requisitos, concebem a arquitetura, desenvolvem os componentes técnicos e asseguram a conformidade com normas e boas práticas. A compreensão deste processo é essencial para contextualizar a pipeline proposta neste projeto, uma vez que permite identificar os pontos onde a automatização baseada em modelos de linguagem pode oferecer ganhos de eficiência e consistência.

\subsection{Análise de Negócio}

\noindent{A} fase de análise de negócio constitui o ponto de partida do processo de desenvolvimento de software na Trust Systems. Antes de qualquer atividade técnica, a empresa conduz uma avaliação estratégica destinada a determinar se existe uma necessidade real no mercado e se a solução proposta tem viabilidade comercial. Esta etapa envolve a análise do contexto competitivo, da oferta existente, dos modelos de pricing e das oportunidades identificadas, permitindo enquadrar o problema com precisão e estabelecer a relevância da futura solução.\\

\noindent{O} resultado desta avaliação é consolidado num \textit{business case}, que reúne as evidências necessárias para suportar a decisão de avançar ou não com o projeto. Esta análise permite ainda caracterizar três elementos fundamentais que orientam a decisão estratégica, sendo eles os fatores essenciais que a solução deve satisfazer (\textit{Key Satisfactors}), as limitações e condicionantes relevantes que podem restringir o seu desenvolvimento (\textit{Key Constraints}) e os ativos estratégicos necessários para suportar a execução do projeto (\textit{Key Assets}).

\noindent{Com} base no \textit{business case}, a empresa conduz uma avaliação de viabilidade que culmina numa decisão final para avançar ou não com o projeto. Apenas as iniciativas consideradas exequíveis e alinhadas com os objetivos estratégicos da organização avançam para a fase seguinte. A sequência destas etapas encontra-se sintetizada na Figura \ref{fig:analise-negocio}, que representa o fluxo de análise de negócio adotado na Trust Systems.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.15\textheight, width=0.4\textwidth]{../../img/market_analysis.png}
    \caption{Processo de análise de negócio na Trust Systems.}
    \label{fig:analise-negocio}
\end{figure}

\subsection{Requisitos, Design e Arquitetura}

Após a decisão formal de avançar com o projeto e a aceitação do mesmo, a responsabilidade transita para o \textit{Product Owner}, que conduz a definição tecnofuncional da solução em articulação contínua com o cliente. O objetivo é transformar necessidades de negócio em descrições funcionais claras e validadas.

\noindent{A} definição de requisitos abrange vários níveis de detalhe, desde requisitos de alto nível e de utilizador até requisitos funcionais, não funcionais e tecnológicos. Estes últimos estabelecem orientações relacionadas com plataformas, linguagens, integrações e outros constrangimentos técnicos. Todo o processo evolui de forma iterativa, sendo ajustado e validado com o cliente até atingir um estado adequado de maturidade.

\noindent{Com} esta base de entendimento são elaborados os \textit{Mockups \& Design}, que representam visualmente a estrutura, os fluxos de interação e a experiência prevista para o sistema. Estes artefactos tornam explícita a interpretação dos requisitos e são essenciais para assegurar alinhamento antes da continuação do trabalho.\\

\noindent{Nesta} fase inclui-se também a definição da arquitetura do sistema, onde são estabelecidos os padrões estruturais, as camadas funcionais, os modelos de comunicação, os mecanismos de segurança e os requisitos técnicos necessários para garantir consistência, escalabilidade e manutenibilidade. É igualmente aqui que se formalizam as normas, políticas e limitações aplicáveis ao projeto, que variam consoante o domínio e podem incluir referências como normas IEEE, a ISO/IEC 27001, recomendações OWASP para proteção de aplicações web ou diretrizes de acessibilidade baseadas nos níveis A, AA e AAA das WCAG, alinhadas com o enquadramento europeu do EAA.

\medskip\noindent{Importa} também salientar que os produtos desenvolvidos pela Trust Systems inserem-se, maioritariamente, no domínio de sistemas empresariais, caracterizados por uma arquitetura distribuída e modular, com separação clara entre componentes de frontend, backend e camadas de integração. Dependendo da complexidade do sistema e dos requisitos do projeto, estas soluções podem assumir a forma de monólitos modulares ou arquiteturas baseadas em serviços, privilegiando a escalabilidade, a manutenibilidade e a integração com sistemas externos. A Figura \ref{fig:architectural_views} ilustra, de forma simplificada, estas duas abordagens arquiteturais.


\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.3\textheight, width=0.5\textwidth]{../../img/architectural_views.png}
    \caption{Vistas arquiteturais de um monólito modular e de uma arquitetura baseada em serviços.}
    \label{fig:architectural_views}
\end{figure}

\subsection{Especificação da API (OpenAPI)}

\noindent{Após} a validação dos \textit{Mockups} e a estabilização dos requisitos funcionais, é definida a especificação da API em formato OpenAPI. Este documento descreve os endpoints, modelos de dados, parâmetros e regras de validação, funcionando como contrato técnico entre as diferentes componentes do sistema.

\noindent{Por} representar de forma estruturada todas as operações previstas, a API serve como base para o desenvolvimento backend e para a implementação frontend, assegurando consistência entre o comportamento esperado e a lógica construída nas fases seguintes.

\subsection{Desenvolvimento Backend}

\noindent{O} desenvolvimento backend na Trust Systems assenta numa estrutura organizacional bem definida, refletida nos projetos gerados com recurso ao JHipster\footnote{\url{https://www.jhipster.tech/}}. Esta ferramenta automatiza a criação da arquitetura base e origina uma separação clara por camadas, com diretórios dedicados a \textit{domain}, \textit{repository}, \textit{service} e \textit{web}, garantindo uma organização consistente e alinhada com boas práticas de engenharia de software. Cada camada assume responsabilidades distintas, onde o domínio modela as entidades da aplicação, os repositórios tratam da persistência de dados, os serviços concentram a lógica de negócio e a camada web expõe os controladores responsáveis pela comunicação com a API.

\noindent{O} backend é construído a partir da especificação OpenAPI previamente validada, que define os endpoints, os modelos de dados e os contratos de comunicação. Com base nessa descrição são implementados os controladores, serviços e repositórios necessários ao funcionamento da aplicação, assegurando correspondência direta entre a API definida e a lógica do sistema. Esta abordagem reduz ambiguidades, promove a rastreabilidade entre requisitos e implementação e facilita a evolução posterior do sistema.\\

\noindent{A} componente de persistência utiliza habitualmente bases de dados relacionais, sendo o PostgreSQL\footnote{\url{https://www.postgresql.org/}} uma das tecnologias mais frequentes nos projetos da empresa. A modelação e inspeção da base de dados é frequentemente apoiada pelo DBeaver\footnote{\url{https://dbeaver.io/}}, que facilita o acompanhamento do esquema e das operações realizadas durante o desenvolvimento.

\noindent{O} processo de execução é suportado pelos mecanismos habituais do ecossistema Java, recorrendo ao Maven\footnote{\url{https://maven.apache.org/}} para compilar, gerar artefactos e executar a aplicação localmente. Para complementar esta explicação, a Figura \ref{fig:endpoint-flow} ilustra o percurso típico de um endpoint, começando na especificação OpenAPI e terminando na camada de repositório. Esta representação visual evidencia a separação de responsabilidades entre as várias camadas e o modo como o backend materializa o contrato definido na especificação.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.15\textheight, width=0.35\textwidth]{../../img/backend_endpoint.pdf}
    \caption{Fluxo típico de implementação de um endpoint no backend.}
    \label{fig:endpoint-flow}
\end{figure}

\subsection{Desenvolvimento Frontend}

\noindent{O} desenvolvimento frontend na Trust Systems segue práticas que asseguram organização, consistência e facilidade de manutenção. Os projetos são desenvolvidos em Angular\footnote{\url{https://angular.io/}} e estruturados de forma modular em diretórios \textit{core}, \textit{development} e \textit{shared}. O \textit{core} reúne elementos essenciais da aplicação, como serviços globais e configurações. O \textit{development} organiza as funcionalidades específicas do produto em desenvolvimento. O \textit{shared} agrega componentes, modelos e utilitários reutilizáveis em vários projetos, garantindo consistência e evitando duplicação de código.\\

\noindent{A} comunicação com o backend é realizada através de serviços Angular dedicados, responsáveis por encapsular as chamadas à API definida na especificação OpenAPI. Estes serviços centralizam o acesso a dados e fornecem métodos bem definidos para consumo pela interface, garantindo separação entre lógica de apresentação e lógica de comunicação.

\noindent{Cada} página da aplicação corresponde a um componente Angular, que solicita a informação necessária ao serviço respetivo. O serviço estabelece a comunicação com a API, interpreta a resposta recebida e devolve os dados ao componente, sendo que este irá prepará-los para serem apresentados. Esta abordagem reduz acoplamento, facilita testes e contribui para a evolução sustentada da aplicação.

\noindent{A} Figura \ref{fig:frontend-flow} ilustra o fluxo típico seguido no frontend entre componentes, serviços e a API.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.18\textheight, width=0.3\textwidth]{../../img/frontend_process.png}
    \caption{Fluxo de interação entre componente, serviço e API no frontend.}
    \label{fig:frontend-flow}
\end{figure}

\begin{figure*}[htbp]
    \centering
    \includegraphics[height=0.20\textheight, width=0.9\textwidth]{../../img/proposal_pipeline.pdf}
    \caption{Pipeline proposta para a geração automática de artefactos de software e ciclo iterativo de validação humana.}
    \label{fig:proposal_pipeline}
\end{figure*}

\subsection{Testes, Qualidade e Conformidade}

Os testes constituem a etapa final do processo de desenvolvimento e garantem que a solução implementada corresponde ao comportamento definido nas fases anteriores. Na Trust Systems, esta validação ocorre de forma essencialmente manual, assegurando que cada componente cumpre os requisitos funcionais, tecnológicos e de experiência definidos em colaboração com o cliente.

\noindent{No} backend, a verificação centra-se na API gerada a partir da especificação OpenAPI. O Postman\footnote{\url{https://www.postman.com/}} é utilizado para testar os endpoints, validar códigos de resposta, conteúdos devolvidos e comportamento em diferentes cenários. Esta validação permite confirmar que os controladores, serviços e repositórios implementados materializam corretamente o contrato definido pela API.

\noindent{No} frontend, os testes incidem sobretudo na interação com a API e na verificação dos fluxos principais da interface. São validados o consumo dos serviços, o tratamento de respostas e a exibição correta da informação, garantindo que os componentes Angular permanecem alinhados com o comportamento esperado do sistema. Além desta validação funcional, é também utilizado o SonarLint\footnote{\url{https://www.sonarlint.org/}}/ESLint\footnote{\url{https://eslint.org/}} em ambiente local para detetar problemas de qualidade de código, como duplicação, uso de elementos obsoletos ou \textit{code smells}. A aplicação é compilada e testada localmente com \texttt{ng build} e \texttt{npm test}\footnote{\url{https://www.npmjs.com/}}, sendo analisados avisos e erros produzidos durante este processo. Por fim, a solução é testada em ambiente de desenvolvimento, onde são realizados testes manuais adicionais para confirmar o comportamento final do frontend.

\section{Solução Proposta para Automatização do Desenvolvimento de Software} \label{sec:proposta}

\subsection{Visão Geral da Solução}

\noindent{Conforme} descrito na secção anterior, o processo de desenvolvimento de software adotado na Trust Systems compreende um conjunto alargado de fases, nem todas suscetíveis de automatização. Atividades de natureza estratégica e contextual, como a análise de negócio e a avaliação de viabilidade de mercado, dependem fortemente de conhecimento humano, julgamento crítico e interação com \textit{stakeholders}, não sendo, por isso, alvo direto de automatização neste trabalho.

\noindent{A} solução proposta foca-se nas fases do processo onde é possível introduzir suporte automatizado de forma eficaz, nomeadamente na interpretação e refinamento de requisitos, na conceção de interfaces, na definição de especificações de API e na geração de artefactos técnicos associados ao desenvolvimento backend e frontend.

\noindent{Para} esse efeito, é proposta uma \textit{pipeline} que define a arquitetura central da solução desenvolvida neste trabalho, organizando o processo em módulos interligados que produzem e consomem artefactos de forma sequencial. Ao longo do fluxo, são introduzidos pontos de validação que permitem assegurar o alinhamento contínuo com os requisitos funcionais, técnicos e organizacionais da Trust Systems, mitigando riscos associados à geração automática e promovendo a consistência dos resultados obtidos. A Figura \ref{fig:proposal_pipeline} fornece uma visão geral do fluxo completo da pipeline, bem como o ciclo de validação humana que intervém no processo de refinamento.

\subsection{Módulos da Pipeline}

\noindent{As} subseções seguintes descrevem cada um dos módulos mais detalhadamente, evidenciado a responsabilidade de cada um, bem como os artefactos produzidos.

\subsubsection{Interpretador de Requisitos} \label{Gerador_Requisitos}

Este módulo constitui o ponto de entrada da pipeline, sendo responsável por analisar as descrições fornecidas pelo cliente e convertê-las numa representação mais estruturada, como ilustrado na Figura \ref{fig:modulo-requisitos}. O seu papel consiste em interpretar instruções iniciais podendo ser ambíguas e informais e organizá-las de modo a facilitar as etapas posteriores. A estrutura resultante permite que os módulos seguintes operem sobre requisitos mais claros e consistentes, reduzindo a propagação de ambiguidades ao longo do processo.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.08\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/requirements.pdf}
    \caption{Módulo de interpretação de requisitos.}
    \label{fig:modulo-requisitos}
\end{figure}
\subsubsection{Gerador de Interfaces}

O módulo de geração de interfaces transforma os requisitos estruturados em representações de elementos de interface e fluxos de interação, conforme representado na Figura \ref{fig:modulo-interfaces}. Esta etapa permite antecipar a organização funcional do sistema e constitui um ponto de validação precoce, uma vez que as interfaces refletem, visualmente, a interpretação dos requisitos. A saída deste módulo serve de referência para o frontend e também para a definição das APIs, garantindo que existe correspondência entre o que é apresentado ao utilizador e o que o sistema deve disponibilizar enquanto funcionalidade.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.08\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/interfaces.pdf}
    \caption{Módulo de geração de interfaces.}
    \label{fig:modulo-interfaces}
\end{figure}
\subsubsection{Gerador da API}

Com base nas interfaces validadas e na lista de requisitos, este módulo gera a especificação da API, definida de forma a representar o contrato de comunicação entre componentes do sistema, tal como a Figura \ref{fig:modulo-api} ilustra. A API surge apenas após a definição e validação da interface, garantindo alinhamento entre as capacidades expostas e os fluxos identificados nas etapas anteriores. Esta especificação, geralmente expressa em formatos formais como OpenAPI, constitui o elemento estruturante que orienta tanto o backend como o frontend, assegurando consistência entre camadas.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/api.pdf}
    \caption{Módulo de geração da API.}
    \label{fig:modulo-api}
\end{figure}
\subsubsection{Gerador de Backend}

A partir da especificação da API e da lista de requisitos desenvolvida nas etapas anteriores, este módulo gera os componentes de backend necessários ao funcionamento do sistema, conforme ilustrado na Figura \ref{fig:modulo-backend}. Esta geração inclui estruturas de dados, controladores, serviços e demais elementos da lógica de negócio associados aos endpoints definidos. Ao assentar diretamente na especificação da API, o backend produzido mantém-se alinhado com o comportamento esperado do sistema e reduz a probabilidade de inconsistências entre a descrição funcional e a implementação.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/backend.pdf}
    \caption{Módulo de geração do código de backend.}
    \label{fig:modulo-backend}
\end{figure}
\subsubsection{Gerador de Frontend}

O módulo de frontend utiliza a informação proveniente das interfaces e da API para gerar componentes de apresentação e os mecanismos necessários para comunicar com o backend, como ilustrado na Figura \ref{fig:modulo-frontend}. Esta organização permite que a camada de apresentação seja construída de forma alinhada tanto com o design inicial como com o contrato da API, evitando discrepâncias entre o que a interface expõe e o que o sistema efetivamente disponibiliza.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/frontend.pdf}
    \caption{Módulo de geração do código de frontend.}
    \label{fig:modulo-frontend}
\end{figure}
\subsubsection{Gerador de Infraestrutura}

Este módulo é responsável por produzir artefactos relacionados com a execução do sistema, como representado na Figura \ref{fig:modulo-infraestrutura}, incluindo configurações, ficheiros de suporte e componentes necessários para integrar o software em ambientes de desenvolvimento ou produção. A infraestrutura funciona como camada complementar às componentes geradas nas etapas anteriores e assegura que o sistema pode ser executado em condições adequadas, respeitando práticas internas da organização.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/infraestructure.pdf}
    \caption{Módulo de geração da Infraestrutura.}
    \label{fig:modulo-infraestrutura}
\end{figure}
\subsection{Controlo de Qualidade da Pipeline}

Esta secção descreve o processo de controlo de qualidade aplicado aos artefactos produzidos pela pipeline, bem como as técnicas utilizadas para melhorar o desempenho e a fiabilidade do sistema. São apresentados os métodos de avaliação que permitem comparar diferentes combinações de modelos de forma consistente, assim como os mecanismos que asseguram que cada etapa da geração permanece alinhada com os requisitos e com o comportamento esperado.

\subsubsection{Validação\\}

\noindent\textbf{Métricas Automáticas}

\noindent{A} validação automática incide particularmente sobre a qualidade do código produzido, recorrendo a métricas amplamente utilizadas na investigação em geração de código, nomeadamente \textit{CodeBLEU}\cite{CODEBLEU} e \textit{CodeBERTScore}\cite{CODEBERTSCORE}. Estas métricas derivam, respetivamente, de \textit{BLEU}\cite{BLEU} e \textit{BERTScore}\cite{BERTSCORE}, originalmente propostas para tarefas de linguagem natural, tendo sido adaptadas para refletir propriedades sintáticas e semânticas específicas de programas.

\paragraph{CodeBLEU}foi proposta por Ren et al.\cite{CODEBLEU} e constitui uma extensão do \textit{BLEU} tradicional\cite{BLEU}, concebida especificamente para avaliar código gerado automaticamente. Ao contrário do \textit{BLEU} simples, que mede apenas a sobreposição de \textit{n-gramas}, o \textit{CodeBLEU} agrega múltiplas dimensões de análise para refletir propriedades estruturais e semânticas intrínsecas aos programas. A métrica é definida como uma combinação ponderada de quatro componentes distintos:

\begin{equation}
\begin{aligned}
    \text{CodeBLEU} &=
    \alpha \cdot \text{BLEU}
    + \beta \cdot \text{BLEU}_{\text{weighted}} \\
    &\quad
    + \gamma \cdot \text{Match}_{\text{AST}}
    + \delta \cdot \text{Match}_{\text{DF}}.
\end{aligned}
\end{equation}

\noindent{A} componente \textit{BLEU} mantém a métrica original de sobreposição de \textit{n-gramas} entre o código candidato e o código de referência. A componente \(\text{BLEU}_{\text{weighted}}\) introduz um esquema de ponderação que atribui maior peso a palavras-chave da linguagem de programação (por exemplo, \texttt{if}, \texttt{return}, \texttt{class}), refletindo o impacto diferenciado que estes tokens têm na estrutura e funcionamento do programa.

\noindent{Uma} \textit{Abstract Syntax Tree} (AST) constitui a representação estruturada do código, na qual cada nó corresponde a uma construção sintática, como expressões, instruções ou blocos. Estas árvores descrevem a organização hierárquica do programa de forma independente da sua forma textual, permitindo comparar a estrutura sintática entre diferentes fragmentos de código. A componente \(\text{Match}_{\text{AST}}\) explora precisamente esta característica, avaliando a semelhança estrutural entre o candidato e a referência através da correspondência entre as respetivas subárvores, permitindo capturar erros estruturais, como omissões de blocos, incompatibilidades de tipos ou construções sintaticamente incompletas, sendo definida, de forma simplificada, por:
\begin{equation}
\begin{aligned}
\text{Match}_{\text{AST}} 
    &= 
    \frac{\displaystyle \text{total de subárvores coincidentes}}
         {\displaystyle \text{total de subárvores da referência}}
\end{aligned}
\end{equation}

\noindent{Por} sua vez, os grafos de fluxo de dados (\textit{data-flow}) representam a forma como a informação é transmitida e transformada ao longo da execução de um programa, descrevendo as dependências entre variáveis e operações. Estes grafos permitem identificar relações semânticas que não são capturadas apenas pela estrutura sintática, como a origem e propagação de valores ou o modo como diferentes instruções interagem entre si. A componente \(\text{Match}_{\text{DF}}\) recorre precisamente a esta representação para avaliar a similaridade semântica entre o candidato e a referência, comparando os respetivos fluxos de dados associados às variáveis do programa:
\begin{equation}
    \text{Match}_{\text{DF}} =
    \frac{\text{total de fluxos de dados coincidentes}}
         {\text{total de fluxos de dados da referência}}
\end{equation}

\noindent{Desta} forma, é possível distinguir fragmentos de código que são lexicalmente semelhantes, mas que apresentam comportamentos lógicos distintos. Na configuração recomendada pelos autores, os pesos são definidos como \(\alpha = 0.1\), \(\beta = 0.1\), \(\gamma = 0.4\) e \(\delta = 0.4\)\cite{CODEBLEU}, atribuindo maior relevância às componentes sintática e semântica. Os resultados experimentais apresentados no trabalho original evidenciam que o \textit{CodeBLEU} apresenta uma correlação mais elevada com a avaliação humana do que métricas tradicionais baseadas apenas em \textit{BLEU}.

\paragraph{CodeBERTScore}segue a mesma lógica do \textit{BERTScore}\cite{BERTSCORE}, adaptando-o ao domínio da programação através da utilização de modelos de representação de código, como o \textit{CodeBERT}\cite{CODEBERT}. Em vez de se basear apenas na coincidência textual, esta métrica avalia a similaridade entre o código gerado e o código de referência a partir de \textit{embeddings} contextuais, captando relações semânticas que subsistem mesmo quando as duas implementações apresentam diferenças ao nível superficial.

\noindent{Sejam} \(C\) o conjunto de tokens do código candidato e \(R\) o conjunto de tokens da referência e, \(\mathbf{e}_t\), \(\mathbf{e}_r\) os \textit{embeddings} associados a cada token por um modelo pré-treinado. A métrica define valores de \textit{precision} e \textit{recall}, calculando um valor final \text{F1} através da média harmónica entre os dois valores, da seguinte forma:

\begin{equation}
    \text{Precision} =
    \frac{1}{|C|}
    \sum_{t \in C}
    \max_{r \in R}
    \cos\big(\mathbf{e}_t, \mathbf{e}_r\big),
\end{equation}

\begin{equation}
    \text{Recall} =
    \frac{1}{|R|}
    \sum_{r \in R}
    \max_{t \in C}
    \cos\big(\mathbf{e}_r, \mathbf{e}_t\big),
\end{equation}

\begin{equation}
    \text{F1} =
    2 \cdot
    \frac{\text{Precision} \cdot \text{Recall}}
         {\text{Precision} + \text{Recall}}.
\end{equation}

\noindent{Ao} basear-se em representações distribuídas treinadas especificamente em código fonte, o \textit{CodeBERTScore} consegue avaliar a proximidade semântica entre duas soluções, mesmo quando estas utilizam diferentes estruturas de controlo, convenções de nomenclatura ou organizações de código. Esta característica torna a métrica particularmente adequada em cenários em que é expectável a existência de múltiplas implementações corretas para o mesmo problema, complementando assim a avaliação estrutural fornecida pelo \textit{CodeBLEU}\cite{CODEBLEU}.\\

\noindent\textbf{Validação humana}

\noindent{Para} além das métricas automáticas, a avaliação da qualidade dos artefactos gerados integra igualmente uma componente de apreciação humana. A análise por parte de um avaliador permite identificar aspetos que não são totalmente captados pelas métricas quantitativas, tais como clareza, adequação ao enunciado, legibilidade e conformidade com boas práticas de programação. A inclusão desta dimensão qualitativa assegura que a comparação entre diferentes combinações de modelos não se limita à proximidade numérica relativamente ao código de referência.

\noindent{Deste} modo, a avaliação final resulta da combinação equilibrada entre métricas automáticas e julgamento humano, garantindo uma análise mais completa e representativa da qualidade global das soluções geradas.

\subsubsection{Refinamento}

O processo de refinamento tem como objetivo melhorar progressivamente a qualidade dos artefactos produzidos pela pipeline, garantindo que estes evoluem de acordo com os requisitos definidos e com as expectativas do utilizador. Este processo assenta em duas componentes complementares, o ciclo de validação humana e a aplicação sistemática de técnicas de \textit{prompt engineering} antes da execução de cada módulo.

\noindent{A} validação humana constitui um mecanismo central deste processo. Após a geração de cada artefacto por parte do respetivo modelo, o resultado é analisado por um avaliador, que determina se este é adequado ou se necessita de ajustamentos. Sempre que o artefacto não cumpre os critérios esperados, o avaliador fornece orientações explícitas que descrevem os aspetos a corrigir. Este feedback é então reintegrado no sistema, originando uma nova iteração de geração. O processo repete-se até que o avaliador considere que o artefacto atinge um nível de qualidade satisfatório. Este ciclo iterativo, ilustrado no canto inferior direito da Figura \ref{fig:proposal_pipeline}, permite incorporar de forma contínua a interpretação humana e assegurar que o sistema se adapta às necessidades específicas do contexto.

\noindent{Para} além da validação humana, o refinamento é reforçado pela aplicação sistemática de técnicas de \textit{prompt engineering} na entrada de cada módulo da pipeline. Estas técnicas orientam o comportamento dos modelos de linguagem, reduzindo ambiguidades e aumentam a precisão, completude e consistência das respostas. A preparação cuidadosa dos pedidos pode incluir a definição de papéis, a formulação estruturada das instruções, a inclusão de exemplos (\textit{few-shot prompting}), a imposição de restrições explícitas ou outras estratégias adequadas ao tipo de artefacto a gerar. Nos diagramas apresentados ao longo desta dissertação, a aplicação destas técnicas é assinalada pelo ícone de duas engrenagens colocado antes de cada modelo, simbolizando que a geração de cada artefacto é antecedida por um conjunto de instruções cuidadosamente formuladas para orientar o comportamento do LLM.

\noindent{A} combinação entre validação humana iterativa e técnicas de \textit{prompt engineering} confere ao processo de refinamento uma natureza adaptativa. Cada iteração incorpora o feedback obtido e melhora o comportamento subsequente dos modelos, promovendo a convergência para artefactos mais completos, precisos e alinhados com o objetivo final da pipeline. Deste modo, o refinamento não apenas complementa a validação automática discutida anteriormente, como assegura um controlo de qualidade dinâmico e sensível ao contexto ao longo de todo o fluxo de geração.

\subsection{Ferramentas de Suporte à Pipeline}

\noindent{A} pipeline proposta será implementada recorrendo a uma ferramenta de orquestração de processos, cuja seleção será efetuada com base num conjunto de critérios previamente definidos. Entre esses critérios incluem-se a facilidade de utilização, a capacidade de integração com diferentes modelos e fornecedores de LLMs, os custos associados e as garantias oferecidas ao nível da privacidade e tratamento de dados. Exemplos de ferramentas que se enquadram neste tipo de soluções são plataformas de orquestração de pipelines de LLMs como o Dify ou o LangFlow, que permitem estruturar fluxos de geração, gerir prompts e integrar múltiplos modelos de forma controlada.\par
\noindent{A} ferramenta de orquestração assume o papel de camada de controlo da pipeline, sendo responsável por coordenar a execução das diferentes etapas, gerir os prompts associados a cada módulo e integrar mecanismos de validação e refinamento iterativo. No interior desta ferramenta serão configuradas integrações com diferentes fornecedores de modelos de linguagem, que serão utilizados para executar as tarefas específicas de cada módulo da pipeline. Deste modo, a ferramenta de orquestração não é responsável pela geração direta dos artefactos finais, mas pela organização e controlo do processo que governa a utilização dos LLMs, assegurando coerência, rastreabilidade e alinhamento entre as várias fases do processo de desenvolvimento.


\section{Planeamento do Trabalho} \label{sec:planeamento}

\noindent{O} trabalho a desenvolver na fase seguinte da dissertação organiza-se em três grandes etapas.\par

\noindent{A} primeira etapa consiste no desenvolvimento do protótipo. Nesta fase será implementada a \textit{pipeline} proposta,  definindo, integrando e articulando os diferentes módulos que serão necessários para a geração de artefactos das diferentes etapas de desenvolvimento de software. Esta fase culminará numa primeira versão funcional da solução.\par

\noindent{Segue-se} uma etapa de avaliação e testes, durante a qual serão analisados os resultados produzidos pela \textit{pipeline}. Serão comparadas diferentes estratégias de prompting e avaliados diversos modelos de linguagem. Esta fase inclui também o refinamento e melhoria da solução sempre que necessário, garantindo maior coerência entre os artefactos gerados e maior robustez no comportamento da pipeline.\par

\noindent{Por} fim, terá lugar a redação e revisão do documento final, que incorpora a consolidação dos resultados obtidos, a descrição detalhada da metodologia seguida e a discussão das limitações e contributos do trabalho.\par

\noindent A Tabela \ref{tableCronograma} apresenta o cronograma das atividades previstas, 
permitindo visualizar a sequência das fases do trabalho e o tempo alocado a cada etapa do projeto.

\begin{table}[H]
\centering
\begin{tabular}{|p{3cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|} 
\hline
\rowcolor{headergray}
\textbf{Descrição das atividades} & \textbf{Jan 26} & \textbf{Fev 26} & \textbf{Mar 26} & \textbf{Abr 26} & \textbf{Mai 26} & \textbf{Jun 26} \\
\hline
\cellcolor{headergray}Desenvolvimento do protótipo & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \cellcolor{ganttblue} & & \\ 
\hline
\cellcolor{headergray}Avaliação e testes & & & & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \\ 
\hline
\cellcolor{headergray}Análise e ajuste do protótipo & & & & & \cellcolor{ganttblue} & \\ 
\hline
\cellcolor{headergray}Redação do documento final & & & & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \cellcolor{ganttblue} \\ 
\hline
\cellcolor{headergray}Revisão final da tese e preparação da defesa & & & & & & \cellcolor{ganttblue} \\ 
\hline
\end{tabular} 
\caption{Cronograma de atividades}
\label{tableCronograma}
\end{table}

%%\section{«Other Section(s) as Appropriate»} \label{sec:work1}

%%The report should include one or more sections providing a detailed description of the problem you are addressing in the project and your plan to tackle it. Use appropriate section titles for what is presented. 

%%You should explain the methods you are planning to use, or have already started to apply, in your project. 

%%This discussion should be grounded in the related work, your own understanding of the problem, and, when available, preliminary results.

%%In case you already have some preliminary results, consider to include a section devoted to them. This section should  describe the work already carried out, what data has already been collected, what analysis and designs have already been done, what methods have been used, what programs and/or preliminary results already exist, etc.

%%\section{Forthcoming Work and Conclusions} \label{sec:conclusions}

%%This section should include subsections describing the work to be carried out during the remainder of the school year and its objectives. 
%
%%It should also present a chronological plan for the completion of the project. 
%
%%Finally, include a concluding subsection that summarizes the contributions already made, provides a preliminary self-assessment of the progress achieved so far, and discusses the main difficulties encountered.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

\end{document}
