%%
%% This is file `sample-sigchi.tex',
%% generated with the docstrip utility.
%% but modified by the faculty @ DI/FCUL
%% The original source files were:
%%
%% samples.dtx  (with options: `sigchi')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigchi.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigplan]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{array}
\usepackage{multirow}
\usepackage{placeins}
\usepackage[table]{xcolor}
\usepackage{tabularx}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta}
\definecolor{headergray}{RGB}{220, 230, 236} % Azul acinzentado muito suave
\definecolor{ganttblue}{RGB}{110, 155, 180}

\usepackage[portuguese]{babel}
\renewcommand{\figurename}{Figura}
\renewcommand{\abstractname}{Resumo}
\makeatletter
\def\fps@figure{htbp}
\makeatother


%% end of the preamble, start of the body of the document source.
\begin{document}

\title{Construção de um Modelo de Desenvolvimento/Geração de Código com IA} 

\author{Gustavo Orlando Costa dos Santos Henriques - 64361}
\affiliation{%
 \institution{
  Estudo Orientado \\ 
  Mestrado em Engenharia Informática \\ 
  Faculdade de Ciências, Universidade de Lisboa}
 }
\email{fc64361@alunos.fc.ul.pt}


\begin{abstract}
Os avanços recentes na inteligência artificial generativa têm permitido automatizar partes do desenvolvimento de software. No entanto, a adoção destas tecnologias em contextos empresariais exige a sua adaptação a práticas internas e fluxos de trabalho já estabelecidos. Esta dissertação, desenvolvida em colaboração com a Trust Systems, tem como objetivo analisar, selecionar e combinar tecnologias de inteligência artificial, para construir uma \textit{pipeline} que automatize etapas relevantes do processo de desenvolvimento de software da empresa. O estudo inclui a utilização de técnicas de \textit{prompt engineering} que assegurem a qualidade e coerência dos artefactos gerados.\\\\
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\noindent\textit{\textbf{Palavras-chave}} \textit{Inteligência artificial; Grandes modelos de linguagem (LLMs); Engenharia de prompts; Geração automática de código; Engenharia de software}
\end{abstract}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
\pagestyle{plain} % removes running headers
\section{Introdução}

%%Context - What is the scientific/technological context of the topic of your project?
\noindent{A} inteligência artificial generativa tem vindo a transformar várias etapas do processo de desenvolvimento de software, permitindo automatizar tarefas que tradicionalmente exigiam significativa intervenção humana\cite{LLM4SE}. Modelos de linguagem de grande escala tornaram-se capazes de interpretar instruções e gerar código a partir dessas descrições\cite{Codex}, bem como produzir explicações, documentação e outros artefactos associados ao ciclo de vida do software\cite{GPT4Experiments}.\par

%%Problem - What is the original problem your addressed in your project?
\noindent{Apesar} do crescimento destas tecnologias, o desafio é conseguir adaptar as mesmas de forma eficaz ao processo concreto de desenvolvimento utilizado em contextos empresariais. O problema abordado nesta dissertação consiste, portanto, em aplicar, adaptar e combinar tecnologias de inteligência artificial, de forma a automatizar etapas do processo de desenvolvimento de software da Trust Systems, garantindo alinhamento com os seus métodos e constrangimentos operacionais.\\\par

\noindent\textbf{Motivação}

\noindent{A} automatização de partes do desenvolvimento de software pode trazer benefícios significativos para a empresa, nomeadamente a redução de esforço manual\cite{CopilotStudy}, aceleração da prototipagem e maior capacidade de resposta a requisitos em evolução. No contexto da Trust Systems, onde a manipulação de dados sensíveis impõe restrições adicionais ao uso de plataformas externas, torna-se particularmente relevante compreender como integrar soluções baseadas em modelos de linguagem de forma controlada, segura e compatível com o processo atual. Esta investigação procura, assim, apoiar a adoção responsável e eficiente destas tecnologias no ambiente real da empresa.\\\par

\noindent\textbf{Objetivo}

\noindent{O} objetivo geral desta dissertação é desenvolver e avaliar uma \textit{pipeline} modular que utilize tecnologias de inteligência artificial, nomeadamente modelos de linguagem, para automatizar etapas relevantes do processo de desenvolvimento de software da Trust Systems. Os objetivos específicos incluem:

\begin{itemize}
    \item Avaliar tecnologias existentes de IA e selecionar as mais adequadas ao contexto interno;
    \item Definir e implementar uma \textit{pipeline} baseada em \textit{prompt engineering};
    \item Gerar artefactos relevantes, como especificações, design e código;
    \item Avaliar a qualidade das saídas produzidas e comparar diferentes estratégias de prompting.
\end{itemize}

\noindent\textbf{Outline.} How is the rest of the document structured? \\The remainder of this document is organised as follows. Section \ref{sec:background} presents bla bla bla. ...

\section{Enquadramento Teórico} \label{sec:background}

Esta secção serve como base teórica para clarificar alguns conceitos importantes para o projeto, permitindo uma melhor compreensão das secções que se seguem.\\\par

%%In this section, you should describe the scientific or technological context of your project. Provide enough information so that a reader unfamiliar with the topic can understand the problem you are addressing and the rationale for your project. This may include relevant concepts and definitions in the area, particularly those that will be used throughout this document.

\noindent\textbf{Geração automática de código}\par
\noindent{A} geração automática de código consiste no processo de produzir código fonte de forma parcial ou integral a partir de descrições de mais alto nível, como requisitos em linguagem natural, esquemas visuais, modelos formais ou exemplos estruturados. Em vez de o programador escrever manualmente o código fonte, recorre-se a sistemas capazes de interpretar estas descrições e traduzir o seu conteúdo para implementações concretas, acelerando o desenvolvimento e reduzindo tarefas repetitivas.\par

\noindent{Apesar} da geração automática de código estar hoje em dia associada à inteligência artificial generativa, a ideia não é propriamente nova. A geração de código foi endereçada anteriormente por abordagens como o Model-Driven Engineering (MDE), onde o código é gerado a partir de modelos formais, como por exemplo diagramas ou estruturas abstratas\cite{MDE-Schmidt,MDEInPratice} ou linguagens específicas de domínio (DSLs), que permitem escrever descrições declarativas que depois são traduzidas automaticamente para código\cite{DSLs}. Contudo, estas técnicas dependem de regras de transformação rígidas e gramáticas estritamente definidas, o que as torna eficazes apenas em domínios muito controlados e pouco adaptáveis a requisitos mais abertos ou expressos em linguagem natural.\\\par

\noindent{Os} modelos de IA generativa, os quais se tornaram oficialmente disponíveis em 2022, proporcionaram uma evolução significativa na geração automática de código ao permitirem interpretar instruções menos estruturadas, como texto em linguagem natural\cite{Codex}. Esta capacidade resulta do facto de estes modelos serem treinados em grandes volumes de dados heterogéneos, que incluem código fonte, documentação técnica, exemplos de implementação e descrições presentes em fóruns de programação. A exposição simultânea a linguagem natural e a linguagens de programação permite que os modelos aprendam padrões sintáticos, estruturas típicas de implementação e relações entre diferentes componentes de um programa.\\

\noindent{Uma} parte importante desta evolução deve-se à arquitetura \textit{Transformer}, proposta em 2017 por Vaswani et al.\cite{Transformer}. Como ilustrado na Figura \ref{fig:transformer}, os \textit{Transformer} utilizam mecanismos de atenção que identificam, dentro de uma sequência de texto, as partes mais relevantes para cada token, capturando dependências longas e relações complexas entre elementos da instrução. Esta arquitetura revelou-se altamente eficiente para tarefas de processamento de linguagem natural e tornou possível, nos anos seguintes, treinar modelos de grande escala capazes de compreender instruções complexas e gerar código coerente e funcional\cite{Codex}.\\

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.4\textheight, width=0.3\textwidth]{../../img/transformer.png}
    \caption{Arquitetura Transformer proposta por Vaswani et al.\cite{Transformer}}
    \label{fig:tansformer}
\end{figure}

\noindent{Ao} longo dos últimos três anos têm surgido cada vez mais sistemas que exploram o potencial dos modelos de linguagem para apoiar ou automatizar partes do processo de desenvolvimento de software. Alguns destes sistemas recorrem a um único modelo para interpretar descrições e gerar código de forma direta, enquanto outros combinam vários modelos ou etapas especializadas para orientar, validar ou complementar a geração. Esta diversidade reflete a maturidade crescente da área e o interesse em integrar modelos de linguagem não só como geradores de código, mas também como assistentes ativos no fluxo de trabalho do programador. Exemplos representativos destas abordagens são discutidos de forma detalhada na secção \ref{CODE_GENERATION_TR}.\\\par

\noindent\textbf{Ciclo de Vida do Desenvolvimento de Software}\par

\noindent{Embora} os avanços nos LLMs demonstrem o seu potencial para a geração de código, a construção de um produto de software envolve um conjunto mais amplo de fases. Para contextualizar o impacto e o papel que a automatização pode assumir, é necessário compreender o ciclo de vida completo do desenvolvimento de software\cite{ALLLIFECYCLE}, identificando as fases onde é possível introduzir automatização. Antes de existir código, é necessário definir o que deve ser construído e como o sistema deve funcionar. Após a implementação, existem ainda outros passos a cumprir para que se garanta a qualidade e a continuidade do produto.\\\par

\noindent{Estas} etapas incluem, em primeiro lugar, a elicitação e análise de requisitos, que visam garantir que as necessidades do cliente sejam adequadamente compreendidas, estruturadas e documentadas. O processo de elicitação de requisitos envolve diversas técnicas, incluindo entrevistas e revisões literárias, como evidenciado por Lim et al.\cite{RE}, que destacam a importância de métodos eficazes para alcançar uma compreensão abrangente das necessidades dos utilizadores, uma vez que os requisitos devidamente capturados constituem a base sobre a qual todo o ciclo de vida do software é construído.\par

\noindent{Com} os requisitos definidos, a modelação funcional e estrutural do sistema surge como etapa subsequente, frequentemente suportada por linguagens formais de representação como a UML (Unified Modeling Language). A UML permite traduzir requisitos textuais em representações visuais, facilitando a análise, validação e comunicação entre equipas técnicas e não técnicas. Berenbach\cite{UML} destaca que os modelos UML desempenham um papel crítico na documentação e validação de requisitos, servindo como elementos centrais de coordenação entre diferentes perspetivas do sistema. Esta modelação inclui diagramas de casos de uso, classes, atividades ou sequência, que complementam a descrição funcional do sistema e ajudam a antecipar o comportamento desejado. A conceção de interfaces e fluxos de interação beneficia igualmente destas representações estruturadas.\par

\noindent{A} definição de APIs (Application Programming Interfaces) e dos componentes arquiteturais constitui outra etapa fundamental, pois estabelece os contratos de comunicação entre as diferentes partes do sistema. Especificações claras de APIs permitem uma implementação mais consistente, facilitam a integração entre módulos e suportam estratégias de teste orientadas a componentes e serviços.

\noindent{Depois} da definição dos componentes e das interfaces do sistema, segue-se a fase de implementação, onde o código é desenvolvido de acordo com as especificações definidas. Esta etapa envolve não apenas a programação propriamente dita, mas também a integração entre módulos e a resolução de dependências técnicas, garantindo que os componentes funcionem de forma coesa. A implementação é acompanhada por atividades de verificação e validação, onde se aplicam diferentes níveis de testes, com o objetivo de identificar defeitos, avaliar comportamentos e assegurar que o software cumpre os requisitos estabelecidos. Por fim, a documentação técnica desempenha um papel transversal a todas estas fases, registando decisões, especificações, arquiteturas, APIs e procedimentos de utilização, facilitando a manutenção futura e promovendo uma compreensão consistente do sistema entre programadores e stakeholders.\\\par

\noindent{Para} além das fases que compõem o desenvolvimento de software, importa considerar também as metodologias que organizam estas atividades ao longo do ciclo de vida. Os processos tradicionais, como o modelo em cascata (Waterfall)\cite{Waterfall}, estruturavam o desenvolvimento de forma sequencial, com transições rígidas entre etapas. Com o tempo, esta abordagem revelou limitações em cenários de requisitos dinâmicos, particularmente em contextos de mudança frequente ou incerteza elevada, conduzindo à adoção de metodologias ágeis, que promovem ciclos iterativos, entregas incrementais e adaptação contínua às necessidades do utilizador\cite{Agile}, como ilustrado na Figura \ref{fig:waterfall_agile}.\\\par

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.2\textheight, width=0.45\textwidth]{../../img/waterfall_agille.png}
    \caption{Comparação entre o modelo Waterfall e uma abordagem Agile}
    \label{fig:waterfall_agile}
\end{figure}

\noindent\textbf{Limitações dos LLMs e Técnicas de Refinamento} \label {PE-BACKGROUND}

\noindent{Apesar} dos avanços significativos alcançados pelos modelos de linguagem de grande escala, estes sistemas apresentam limitações que afetam diretamente a sua aplicação no desenvolvimento de software. Entre os desafios mais comuns encontram-se a geração de código incorreto ou incompleto, inconsistências lógicas, alucinações factuais e dificuldades em interpretar requisitos ambíguos ou instruções pouco estruturadas. Estas limitações resultam, em grande parte, da natureza estatística dos modelos, da variabilidade dos dados de treino e da ausência de mecanismos internos de verificação semântica.\par

\noindent{Para} mitigar estas limitações, diversas técnicas de refinamento têm sido exploradas. Uma abordagem consiste no treino adicional (fine-tuning) sobre dados específicos de um domínio, permitindo ajustar o comportamento do modelo às necessidades de uma organização ou tarefa concreta. No entanto, esta estratégias implica custos elevados, sobretudo quando envolvem retrainar modelos de larga escala. Cottier et al.\cite{CostIncreaseInLLMS} afirma que o custo associado aos modelos computacionalmente mais intensivos, tem crescido a uma taxa de 2.4 vezes ao ano desde 2016.\\\par

\noindent{Neste} contexto, a engenharia de prompts (prompt engineering) tornou-se uma alternativa particularmente relevante. Estas técnicas procuram otimizar as instruções fornecidas ao modelo, estruturando-as de modo a orientar o comportamento do LLM sem necessidade de treino adicional. Estudos recentes têm demonstrado que a forma como o prompt é construído influencia significativamente a qualidade do código gerado, a clareza das explicações e a capacidade de o modelo seguir passos complexos\cite{CopilotStudy}. Ao estabelecer padrões, estratégias e boas práticas de formulação de prompts\cite{PEinLLMS}, é possível alcançar resultados mais fiáveis e reduzir ambiguidades inerentes à interpretação do modelo. Para além destas boas práticas gerais, a literatura identifica ainda um conjunto variado de técnicas específicas, cada uma concebida para atingir objetivos distintos, esde a melhoria do raciocínio e lógica do modelo, até à redução de alucinações, conforme sistematizado por Sahoo et al.\cite{PETechniques}.\par

\noindent{Dado} que esta dissertação visa explorar a automatização de diferentes etapas do desenvolvimento de software, a engenharia de prompts assume um papel central enquanto mecanismo de controlo e refinamento do comportamento dos modelos utilizados. O baixo custo operacional e a ausência de necessidade de treino especializado tornam esta abordagem particularmente adequada ao contexto estudado, permitindo adaptar modelos generalistas às tarefas específicas que compõem o pipeline de geração de software.\par

\section{Trabalho relacionado} \label{sec:relatedwork}

A presente secção reúne o estado da arte relevante para esta tese, apresentando trabalhos, modelos e ferramentas que abordam problemas relacionados com a aplicação de métodos de inteligência artificial ao desenvolvimento de software, a utilização de técnicas de prompting e avaliação de modelos.\\\par

%%This section should present the state of the art on the topic of your project. It should discuss relevant related work and existing solutions, highlighting their main contributions as well as their limitations, and identifying the gaps or opportunities that motivate your project.

%%Preparing this section will require you to include references to academic papers, books, and possibly online resources. The next paragraph exemplifies how to do it.

%%\medskip

%%In this work, you are expected to follow the guidelines on document preparation presented in Lamport’s book on \LaTeX~\cite{lamport1994latex}. For editing, you may use tools such as the online platform Overleaf~\cite{overleaf}. There is also a good chance that your project will build upon some of Lamport’s many scientific contributions, such as the concept of logical clocks~\cite{lamport1978clocks}.

\noindent\textbf{Geração Automática de Código} \label{CODE_GENERATION_TR}

\noindent{Nesta} secção são analisados trabalhos que ilustram várias abordagens para automatizar a transformação de descrições diretamente em código.\\\par

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.85\textwidth]{../../img/codellama_family.pdf}
    \caption{Pipeline de especialização do Code Llama\cite{CodeLlama}.}
    \label{fig:codellama-pipeline}
\end{figure*}

\noindent{Hoje} em dia já existem vários modelos generativos com a finalidade de desenvolvimento de código, ou seja, modelos que foram construídos com o objetivo principal de gerar como resposta um excerto de código que cumpre os requisitos solicitados pelo ser humano. Codex\cite{Codex}, uma variante do GPT-3\cite{GPT-3} especializada em código, foi um dos primeiros modelos amplamente conhecidos para transformar descrições textuais em código executável, suportando múltiplas linguagens e tarefas como geração de funções, completamento e tradução entre linguagens. Este modelo serviu ainda de base ao GitHub Copilot, que será abordado mais adiante, estabelecendo um marco na utilização prática de LLMs para auxiliar o desenvolvimento de software.\par

\noindent{Dando} seguimento a esta ideia, surgiu o CodeLlama\cite{CodeLlama}, uma família de modelos orientados para tarefas de programação como geração, explicação e preenchimento de código. Estes modelos, que foram desenvolvidos com base no modelo Llama2\cite{Llama2}, são disponibilizados em três variantes distintas especificadas abaixo e na Figura \ref{fig:codellama-pipeline}:

\begin{itemize}
    \item \textbf{Code Llama}, a versão base, implementada para tarefas mais gerais de compreensão e transformação de código;
    \item \textbf{Code Llama - Python}, uma versão treinada adicionalmente com grandes bases de dados de código python, fornecendo um auxílio com mais qualidade em requisitos para esta linguagem em específico;
    \item \textbf{Code Llama - Instruct}, uma variante ajustada para seguir melhor as instruções humanas, oferecendo uma interação conversacional mais aprimorada.
\end{itemize}
\noindent{Treinados} para processar sintaxe estruturada e múltiplos paradigmas de programação, os modelos CodeLlama representam uma alternativa moderna e de acesso aberto (open-source), ideal para cenários que exigem a conversão de requisitos em linguagem natural diretamente para código.\par

\noindent{Adicionalmente}, temos também o StarCoder\cite{StarCoder} e a sua evolução mais recente, StarCoder2\cite{StarCoder2}, que representam modelos treinados em larga escala no dataset The Stack (The Stack v2 para o modelo StarCoder2), destacando-se pelo suporte multilinguagem, capacidades de preenchimento, janelas de contexto alargadas, permitindo, com este último ponto, analisar blocos mais extensos de código numa única passagem, e mecanismos de treino orientados para segurança e transparência. Graças a estas características, tornam-se referências úteis para compreender boas práticas na construção de LLMs orientados para código, tanto ao nível da arquitetura e dos datasets, como das técnicas necessárias para desenvolver sistemas capazes de converter descrições em código de forma fiável e coerente.\\\par

\noindent{Para} além dos modelos dedicados à geração de código, têm surgido ferramentas práticas de assistência ao programador integradas diretamente nas IDEs (ambientes de desenvolvimento integrado). Um exemplo marcante é o GitHub Copilot\footnote{\href{https://github.com/features/copilot}{https://github.com/features/copilot}}, inicialmente alimentado pelo modelo Codex. Com a evolução da ferramenta, o Copilot passou também a incorporar modelos mais avançados, como o GPT-4 e GPT-4o. Hoje em dia já inclui modos autónomos como o modo de agente e o agente de programação, capazes de executar ações dentro da IDE ou desenvolver tarefas completas de forma assistida. Ziegler et al.\cite{GitHubCopilot} estudaram empiricamente a ferramenta analisando o comportamento da mesma e o seu impacto no processo de desenvolvimento, evidenciando como a completamento incremental pode acelerar tarefas de rotina e reduzir o esforço cognitivo do programador.\par

\noindent{De} forma semelhante, a Amazon apresentou o CodeWhisperer\footnote{\href{https://aws.amazon.com/pt/q/developer/}{https://aws.amazon.com/pt/q/developer/}}, um assistente de programação concebido para gerar sugestões de código contextualizadas em múltiplas linguagens. Yetistiren et al.\cite{AmazonCodeWhisperer} compararam o CodeWhisperer com outras ferramentas, incluindo o Copilot e o ChatGPT, avaliando a qualidade, correção e segurança das sugestões produzidas. Tal como o Copilot, o CodeWhisperer opera principalmente como um mecanismo de completamento inteligente dentro da IDE, contribuindo para automatizar partes do fluxo de escrita de código e acelerar tarefas repetitivas.\par

\noindent{A} crescente integração destas ferramentas diretamente nas IDEs mostra que os LLMs estão a ser efetivamente adotados no desenvolvimento de software do dia a dia, sobretudo em cenários de completamento de código. Esta adoção prática tem contribuído para acelerar tarefas rotineiras e aumentar a produtividade dos programadores\cite{CopilotRole}.\\

\noindent{Nos} últimos tempos, surgiram também ferramentas que vão de encontro ao conceito de \textit{Spec-Driven Development} (SDD), onde, em vez de se implementar o código primeiro e documentá-lo posteriormente, começa-se por definir as especificações que irão servir de guia para os agentes de IA. Estas especificações assumem-se como a fonte central de orientação do processo, podendo incluir listas de requisitos, componentes, tarefas e decisões tecnológicas que, em abordagens tradicionais, estariam distribuídas por diversos artefactos de análise e planeamento. Assim, uma parte significativa das atividades que antecedem a implementação, é formalizada diretamente nestes ficheiros. Entre estas destaca-se o Spec-Kit\footnote{\href{https://github.com/github/spec-kit}{https://github.com/github/spec-kit}}, desenvolvido pela equipa de IA do GitHub, uma ferramenta que fornece uma interface de linha de comandos para criar e organizar especificações, planos e tarefas capazes de guiar modelos generativos ao longo de um fluxo de desenvolvimento. De forma complementar, o Kiro\footnote{\href{https://kiro.dev}{https://kiro.dev}}, desenvolvido pela Kiro Labs, apresenta-se como um ambiente integrado que combina edição de especificações com agentes capazes de gerar e atualizar código com base nesses ficheiros estruturados. Embora ainda recentes, ambas as ferramentas ilustram uma nova tendência no desenvolvimento de software onde se criam fluxos automáticos que partem de especificações estruturadas para produzir componentes coerentes.\par

\noindent{Além} destas ferramentas, têm surgido também propostas que abordam este problema recorrendo a especificações formais. Patil et al.\cite{Spec2Code} apresentam o spec2code, um framework que combina modelos de linguagem com verificadores formais para gerar código C a partir de especificações estruturadas. Existe também investigação centrada na geração automática das próprias especificações formais. Um exemplo recente é o SpecGen, proposto por Ma et al.\cite{SpecGen}, que utiliza modelos de linguagem para produzir contratos formais, a partir de código-fonte ou descrições textuais. O sistema gera especificações em linguagens como JML\cite{JML} e avalia a sua consistência e verificabilidade utilizando verificadores formais. O SpecGen demonstra o papel crescente dos LLMs na automatização de etapas tradicionalmente manuais.\\\par

%%\noindent{Para} além das abordagens baseadas em especificações, surgem também trabalhos que seguem caminhos distintos na geração automática de código. Embora não se integrem no mesmo enquadramento teórico, constituem contribuições relevantes por explorarem problemas mais específicos, como a transformação de interfaces visuais em estruturas front-end. Xu et al.\cite{UItoCode} propõem um sistema que converte imagens de interfaces web em código HTML e CSS. O método assenta num fluxo composto por três etapas principais: geração de um dataset com imagens e respetivo código, deteção dos componentes visuais da interface recorrendo a modelos como CNN\cite{CNN} e Faster R-CNN\cite{R-CNN} e, produção do código através de uma arquitetura que combina uma CNN para extração visual com uma LSTM\cite{LSTM} responsável por gerar a sequência de código. Este trabalho demonstra uma abordagem interessante para a transformação do design em estruturas front-end executáveis, alinhando-se com a componente da tese dedicada à geração automática de código para a interface.\\\par

\noindent{A} Figura \ref{fig:timeline-modelos} ilustra a cronologia dos sistemas analisados, apresentando uma linha temporal que sintetiza o seu aparecimento. Contudo, há que ter em conta que atualmente existe um ecossistema muito vasto de ferramentas e modelos generativos orientados a programação que vai muito para além do que foi mencionado nesta secção. A sua evolução tem sido contínua e acelerada, com contribuições de várias organizações como OpenAI, Meta, Google, AWS e a comunidade de código aberto.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.4\textheight, width=0.3\textwidth]{../../img/code_generation_tineline.png}
    \caption{Linha temporal dos modelos e ferramentas de geração de código analisados nesta secção.}
    \label{fig:timeline-modelos}
\end{figure}

\noindent\textbf{Engenharia de Prompts}

Como já foi referido na secção \ref{PE-BACKGROUND}, a forma como as instruções são fornecidas a um modelo de linguagem tem um impacto direto na qualidade do código que o mesmo consegue gerar. Diversos trabalhos mostram que técnicas de engenharia de prompts podem melhorar significativamente o desempenho em tarefas de linguagem natural para código. Esta secção apresenta estudos que aplicam estas técnicas em cenários reais de geração de código, evidenciando a sua importância prática no desenvolvimento de sistemas baseados em LLMs.\\\par

\noindent{Um} dos estudos no contexto da engenharia de prompts aplicada à geração de código é o trabalho de Liu et al.\cite{ChatGPTGenerationPE}, que investiga a forma como diferentes estratégias de prompting influenciam o desempenho do ChatGPT em tarefas de geração de código. Os autores avaliam o modelo no benchmark CodeXGlue, um conjunto de tarefas padronizadas para programação que inclui geração, tradução, refatoração e completamento de código, e demonstram que a formulação do prompt tem um impacto substancial na qualidade do código gerado. O estudo aplica técnicas como \textit{chain-of-thought}, instruções comportamentais e otimizações multi-etapa, mostrando que o desempenho do ChatGPT pode melhorar significativamente. Esta conclusão foi alcançada através de métricas como o BLEU que avalia a semelhança entre o código gerado e a solução de referência através da contagem de n-gramas, isto é, sequências contíguas de n tokens que permitem medir a sobreposição entre as duas versões de código e o CodeBLEU, que amplia a abordagem anterior ao incluir informação específica de programas, analisando não apenas n-gramas mas também a estrutura sintática representada por árvores AST e as relações de fluxo de dados.\\\par

\noindent{Adicionalmente} Wang et al.\cite{PET-SELECT}, afirmam que, apesar dos avanços recentes nos LLMs, continua a ser difícil garantir que estes produzam código correto e robusto de forma consistente. Para mitigar este problema, os autores propõem o PET-Select, um método que seleciona automaticamente a técnica de prompting mais adequada com base na complexidade do problema. Avaliado em benchmarks como MBPP e HumanEval, o PET-Select mostrou melhorias moderadas na qualidade do código e reduções significativas no custo de geração, demonstrando que a escolha informada da estratégia de prompting pode ter impacto real no desempenho de modelos orientados à programação.\\\par

\noindent{Um} outro contributo é apresentado por Khojah et al.\cite{PEIMPACTWITHCODEPROMPTEVAL}, que exploraram o impacto de diferentes técnicas de prompt engineering na geração de código. Os autores introduzem o CodePromptEval, um dataset composto por 7072 prompts concebido para avaliar cinco técnicas distintas (few-shot, persona, chain-of-thought, function signature e list of packages) aplicadas à geração de funções completas em 3 modelos, o GPT-4o, Llama 3 e Mistral. O estudo mostra que algumas destas técnicas influenciam de forma significativa a correção e qualidade do código produzido. Contudo, a combinação de várias técnicas não garante necessariamente melhorias adicionais.\\

\noindent{Para} além das técnicas de prompting aplicadas diretamente ao enunciado da tarefa, existe uma linha de investigação que explora estratégias de closed-loop prompting, onde o modelo é instruído a analisar e refinar o próprio código após a primeira geração. Ding et al.\cite{PECYCLE} apresentam o CYCLE, um método que combina geração inicial com iterações sucessivas de auto-refinamento orientadas por feedback, mostrando melhorias na qualidade final do código. De forma complementar, Zhou et al.\cite{PEREFINERCODE} propõem o RefineCoder, que incorpora um mecanismo adaptativo de crítica e correção para permitir que o LLM identifique e ajuste erros no código que produz. Ambos os trabalhos reforçam que a melhoria iterativa guiada pelo próprio modelo pode ser uma alternativa eficaz às abordagens que dependem exclusivamente do prompt inicial, contribuindo para aumentar a fiabilidade do código gerado.

\section{Processo de Desenvolvimento de Software da Trust Systems}

Esta secção descreve o processo de desenvolvimento de produtos adotado pela Trust Systems, apresentando as principais etapas que estruturam a construção de uma solução desde a sua conceção inicial até à sua validação final. O objetivo é caracterizar o fluxo interno seguido pela empresa, evidenciando a forma como as equipas analisam o mercado, definem requisitos, concebem a arquitetura, desenvolvem os componentes técnicos e asseguram a conformidade com normas e boas práticas. A compreensão deste processo é essencial para contextualizar a pipeline proposta nesta dissertação, uma vez que permite identificar os pontos onde a automatização baseada em modelos de linguagem pode oferecer ganhos de eficiência e consistência.

\subsection{Análise de Negócio}

\noindent{A} fase de análise de negócio constitui o ponto de partida do processo de desenvolvimento de software na Trust Systems. Antes de qualquer atividade técnica, a empresa conduz uma avaliação estratégica destinada a determinar se existe uma necessidade real no mercado e se a solução proposta tem viabilidade comercial. Esta etapa envolve a análise do contexto competitivo, da oferta existente, dos modelos de pricing e das oportunidades identificadas, permitindo enquadrar o problema com precisão e estabelecer a relevância da futura solução.\\

\noindent{O} resultado desta avaliação é consolidado num \textit{business case}, que reúne as evidências necessárias para suportar a decisão de avançar ou não com o projeto. Aqui são analisados o enquadramento de mercado, a oferta e o posicionamento competitivo, bem como o modelo de pricing e o impacto esperado da solução. Esta análise permite ainda caracterizar três elementos fundamentais que orientam a decisão estratégica, sendo eles os fatores essenciais que a solução deve satisfazer (\textit{Key Satisfactors}), as limitações e condicionantes relevantes que podem restringir o seu desenvolvimento (\textit{Key Constraints}) e os ativos estratégicos necessários para suportar a execução do projeto (\textit{Key Assets}).

\noindent{Com} base no \textit{business case}, a empresa conduz uma avaliação de viabilidade que culmina numa decisão final para avançar ou não com o projeto. Apenas as iniciativas consideradas exequíveis e alinhadas com os objetivos estratégicos da organização avançam para a fase seguinte. A sequência destas etapas encontra-se sintetizada na Figura \ref{fig:analise-negocio}, que representa o fluxo de análise de negócio adotado na Trust Systems.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.2\textheight, width=0.5\textwidth]{../../img/market_analysis.png}
    \caption{Processo de análise de negócio na Trust Systems.}
    \label{fig:analise-negocio}
\end{figure}

\subsection{Requisitos, Design e Arquitetura}

Após a decisão formal de avançar com o projeto, a responsabilidade transita para o \textit{Product Owner}, que conduz a definição tecnofuncional da solução em articulação contínua com o cliente. O objetivo é transformar necessidades de negócio em descrições funcionais claras e validadas.

\noindent{A} definição de requisitos abrange vários níveis de detalhe, desde requisitos de alto nível e de utilizador até requisitos funcionais, não funcionais e tecnológicos. Estes últimos estabelecem orientações relacionadas com plataformas, linguagens, integrações e outros constrangimentos técnicos. Todo o processo evolui de forma iterativa, sendo ajustado e validado com o cliente até atingir um estado adequado de maturidade.

\noindent{Com} esta base de entendimento são elaborados os \textit{Mockups \& Design}, que representam visualmente a estrutura, os fluxos de interação e a experiência prevista para o sistema. Estes artefactos tornam explícita a interpretação dos requisitos e são essenciais para assegurar alinhamento antes da continuação do trabalho.\\

\noindent{Nesta} fase inclui-se também a definição da arquitetura do sistema, onde são estabelecidos os padrões estruturais, as camadas funcionais, os modelos de comunicação, os mecanismos de segurança e os requisitos técnicos necessários para garantir consistência, escalabilidade e manutenibilidade. É igualmente aqui que se formalizam as normas, políticas e limitações aplicáveis ao projeto, que variam consoante o domínio e podem incluir referências como normas IEEE, a ISO/IEC 27001, recomendações OWASP para proteção de aplicações web ou diretrizes de acessibilidade baseadas nos níveis A, AA e AAA das WCAG, alinhadas com o enquadramento europeu do EAA.

\subsection{Especificação da API (OpenAPI)}

\noindent{Após} a validação dos \textit{Mockups}, é definida a especificação da API em formato OpenAPI. Este documento descreve os endpoints, modelos de dados, parâmetros e regras de validação, funcionando como contrato técnico entre as diferentes componentes do sistema.

\noindent{Por} representar de forma estruturada todas as operações previstas, a API serve como base para o desenvolvimento backend e para a implementação frontend, assegurando consistência entre o comportamento esperado e a lógica construída nas fases seguintes.

\subsection{Desenvolvimento Backend}

\noindent{O} desenvolvimento backend na Trust Systems assenta numa estrutura organizacional bem definida, refletida nos projetos gerados com recurso ao JHipster. Esta ferramenta automatiza a criação da arquitetura base e origina uma separação clara por camadas, com diretórios dedicados a \textit{domain}, \textit{repository}, \textit{service} e \textit{web}, garantindo uma organização consistente e alinhada com boas práticas de engenharia de software. Cada camada assume responsabilidades distintas, onde o domínio modela as entidades da aplicação, os repositórios tratam da persistência de dados, os serviços concentram a lógica de negócio e a camada web expõe os controladores responsáveis pela comunicação com a API.

\noindent{O} backend é construído a partir da especificação OpenAPI previamente validada, que define os endpoints, os modelos de dados e os contratos de comunicação. Com base nessa descrição são implementados os controladores, serviços e repositórios necessários ao funcionamento da aplicação, assegurando correspondência direta entre a API definida e a lógica do sistema. Esta abordagem reduz ambiguidades, promove a rastreabilidade entre requisitos e implementação e facilita a evolução posterior do sistema.\\

\noindent{A} componente de persistência utiliza habitualmente bases de dados relacionais, sendo o PostgreSQL uma das tecnologias mais frequentes nos projetos da empresa. A modelação e inspeção da base de dados é frequentemente apoiada pelo DBeaver, que facilita o acompanhamento do esquema e das operações realizadas durante o desenvolvimento.

\noindent{O} processo de execução é suportado pelos mecanismos habituais do ecossistema Java, recorrendo ao Maven para compilar, gerar artefactos e executar a aplicação localmente. Para complementar esta explicação, a Figura \ref{fig:endpoint-flow} ilustra o percurso típico de um endpoint, começando na especificação OpenAPI e terminando na camada de repositório. Esta representação visual evidencia a separação de responsabilidades entre as várias camadas e o modo como o backend materializa o contrato definido na especificação.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.2\textheight, width=0.4\textwidth]{../../img/backend_endpoint.png}
    \caption{Fluxo típico de implementação de um endpoint no backend.}
    \label{fig:endpoint-flow}
\end{figure}

\subsection{Desenvolvimento Frontend}

\noindent{O} desenvolvimento frontend na Trust Systems segue práticas que asseguram organização, consistência e facilidade de manutenção. Os projetos são desenvolvidos em Angular e estruturados de forma modular em diretórios \textit{core}, \textit{development} e \textit{shared}. O \textit{core} reúne elementos essenciais da aplicação, como serviços globais e configurações. O \textit{development} organiza as funcionalidades específicas do produto em desenvolvimento. O \textit{shared} agrega componentes, modelos e utilitários reutilizáveis, garantindo consistência e evitando duplicação de código.\\

\noindent{A} comunicação com o backend é realizada através de serviços Angular dedicados, responsáveis por encapsular as chamadas à API definida na especificação OpenAPI. Estes serviços centralizam o acesso a dados e fornecem métodos bem definidos para consumo pela interface, garantindo separação entre lógica de apresentação e lógica de comunicação.

\noindent{Cada} página da aplicação corresponde a um componente Angular, que solicita a informação necessária ao serviço respetivo. O serviço estabelece a comunicação com a API, interpreta a resposta recebida e devolve ao componente os dados já preparados para apresentação. Esta abordagem reduz acoplamento, facilita testes e contribui para a evolução sustentada da aplicação.

\noindent{A} Figura \ref{fig:frontend-flow} ilustra o fluxo típico seguido no frontend entre componentes, serviços e a API.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.23\textheight, width=0.35\textwidth]{../../img/frontend_process.png}
    \caption{Fluxo de interação entre componente, serviço e API no frontend.}
    \label{fig:frontend-flow}
\end{figure}

\subsection{Testes, Qualidade e Conformidade}

Os testes constituem a etapa final do processo de desenvolvimento e garantem que a solução implementada corresponde ao comportamento definido nas fases anteriores. Na Trust Systems, esta validação ocorre de forma essencialmente manual, assegurando que cada componente cumpre os requisitos funcionais, tecnológicos e de experiência definidos em colaboração com o cliente.

\noindent{No} backend, a verificação centra-se na API gerada a partir da especificação OpenAPI. O Postman é utilizado para testar os endpoints, validar códigos de resposta, conteúdos devolvidos e comportamento em diferentes cenários. Esta validação permite confirmar que os controladores, serviços e repositórios implementados materializam corretamente o contrato definido pela API.

\noindent{No} frontend, os testes incidem sobretudo na interação com a API e na verificação dos fluxos principais da interface. São validados o consumo dos serviços, o tratamento de respostas e a exibição correta da informação, garantindo que os componentes Angular permanecem alinhados com o comportamento esperado do sistema. Além desta validação funcional, é também utilizado o SonarLint/ESLint em ambiente local para detetar problemas de qualidade de código, como duplicação, uso de elementos obsoletos ou \textit{code smells}. A aplicação é compilada e testada localmente com \texttt{ng build} e \texttt{npm test}, sendo analisados avisos e erros produzidos durante este processo. Por fim, a solução é testada em ambiente de desenvolvimento, onde são realizados testes manuais adicionais para confirmar o comportamento final do frontend.

\section{Pipeline Proposta}

\begin{figure*}[htbp]
    \centering
    \includegraphics[height=0.20\textheight, width=0.6\textwidth]{../../img/proposal_pipeline.pdf}
    \caption{Pipeline proposta para a geração automática de artefactos de software.}
    \label{fig:proposal_pipeline}
\end{figure*}

\noindent{A} pipeline proposta define a arquitetura central deste trabalho para automatizar etapas do processo de desenvolvimento de software. Esta secção apresenta a mesma, descrevendo a sua organização modular, o papel de cada componente e a forma como os diferentes módulos interagem ao longo do processo. Explica-se também os mecanismos de validação e refinamento que, não só asseguram a consistência do processo como aumentam o seu potencial. A Figura \ref{fig:proposal_pipeline} fornece uma visão geral do fluxo completo da pipeline, enquanto a Figura \ref{fig:human-validation} ilustra o ciclo de validação humana que intervém no processo de refinamento.

\subsection{Módulos da Pipeline}

\noindent{A} solução foi concebida para integrar modelos de linguagem em diferentes fases do ciclo de desenvolvimento, articulando a geração automática com mecanismos de validação e refinamento iterativo. Desta forma, cada módulo da pipeline assume uma responsabilidade específica, consumindo e produzindo artefactos que alimentam o módulo seguinte, enquanto a validação humana e o refinamento asseguram que o processo permanece alinhado com os requisitos funcionais e com as práticas internas da Trust Systems. As subseções seguintes descrevem cada um dos módulos mais detalhadamente.

\subsubsection{Interpretador de Requisitos} \label{Gerador_Requisitos}

Este módulo constitui o ponto de entrada da pipeline, sendo responsável por analisar as descrições fornecidas pelo cliente e convertê-las numa representação mais estruturada, como ilustrado na Figura \ref{fig:modulo-requisitos}. O seu papel consiste em interpretar instruções iniciais podendo ser ambíguas e informais e organizá-las de modo a facilitar as etapas posteriores. A estrutura resultante permite que os módulos seguintes operem sobre requisitos mais claros e consistentes, reduzindo a propagação de ambiguidades ao longo do processo.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.08\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/requirements.pdf}
    \caption{Módulo de interpretação de requisitos.}
    \label{fig:modulo-requisitos}
\end{figure}
\subsubsection{Gerador de Interfaces}

O módulo de geração de interfaces transforma os requisitos estruturados em representações de elementos de interface e fluxos de interação, conforme representado na Figura \ref{fig:modulo-interfaces}. Esta etapa permite antecipar a organização funcional do sistema e constitui um ponto de validação precoce, uma vez que as interfaces refletem, visualmente, a interpretação dos requisitos. A saída deste módulo serve de referência para o frontend e também para a definição das APIs, garantindo que existe correspondência entre o que é apresentado ao utilizador e o que o sistema deve disponibilizar enquanto funcionalidade.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.08\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/interfaces.pdf}
    \caption{Módulo de geração de interfaces.}
    \label{fig:modulo-interfaces}
\end{figure}
\subsubsection{Gerador da API}

Com base nas interfaces validadas e na lista de requisitos, este módulo gera a especificação da API, definida de forma a representar o contrato de comunicação entre componentes do sistema, tal como a Figura \ref{fig:modulo-api} ilustra. A API surge apenas após a definição e validação da interface, garantindo alinhamento entre as capacidades expostas e os fluxos identificados nas etapas anteriores. Esta especificação, geralmente expressa em formatos formais como OpenAPI, constitui o elemento estruturante que orienta tanto o backend como o frontend, assegurando consistência entre camadas.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/api.pdf}
    \caption{Módulo de geração da API.}
    \label{fig:modulo-api}
\end{figure}
\subsubsection{Gerador de Backend}

A partir da especificação da API e da lista de requisitos desenvolvida nas etapas anteriores, este módulo gera os componentes de backend necessários ao funcionamento do sistema, conforme ilustrado na Figura \ref{fig:modulo-backend}. Esta geração inclui estruturas de dados, controladores, serviços e demais elementos da lógica de negócio associados aos endpoints definidos. Ao assentar diretamente na especificação da API, o backend produzido mantém-se alinhado com o comportamento esperado do sistema e reduz a probabilidade de inconsistências entre a descrição funcional e a implementação.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/backend.pdf}
    \caption{Módulo de geração do código de backend.}
    \label{fig:modulo-backend}
\end{figure}
\subsubsection{Gerador de Frontend}

O módulo de frontend utiliza a informação proveniente das interfaces e da API para gerar componentes de apresentação e os mecanismos necessários para comunicar com o backend, como ilustrado na Figura \ref{fig:modulo-frontend}. Esta organização permite que a camada de apresentação seja construída de forma alinhada tanto com o design inicial como com o contrato da API, evitando discrepâncias entre o que a interface expõe e o que o sistema efetivamente disponibiliza.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/frontend.pdf}
    \caption{Módulo de geração do código de frontend.}
    \label{fig:modulo-frontend}
\end{figure}
\subsubsection{Gerador de Infraestrutura}

Este módulo é responsável por produzir artefactos relacionados com a execução e implantação do sistema, como representado na Figura \ref{fig:modulo-infraestrutura}, incluindo configurações, ficheiros de suporte e componentes necessários para integrar o software em ambientes de desenvolvimento ou produção. A infraestrutura funciona como camada complementar às componentes geradas nas etapas anteriores e assegura que o sistema pode ser executado em condições adequadas, respeitando práticas internas da organização.
\begin{figure}[H]
    \centering
    \includegraphics[height=0.13\textheight, width=0.3\textwidth]{../../img/pipeline_proposal_modules/infraestructure.pdf}
    \caption{Módulo de geração da Infraestrutura.}
    \label{fig:modulo-infraestrutura}
\end{figure}
\subsection{Controlo de Qualidade da Pipeline}

Esta secção descreve o processo de controlo de qualidade aplicado aos artefactos produzidos pela pipeline, bem como as técnicas utilizadas para melhorar o desempenho e a fiabilidade do sistema. São apresentados os métodos de avaliação que permitem comparar diferentes combinações de modelos de forma consistente, assim como os mecanismos que asseguram que cada etapa da geração permanece alinhada com os requisitos e com o comportamento esperado.

\subsubsection{Validação}

\hspace*{1.5em}\textbf{Métricas Automáticas}

\noindent{A} validação automática incide particularmente sobre a qualidade do código produzido, recorrendo a métricas amplamente utilizadas na investigação em geração de código, nomeadamente \textit{CodeBLEU}\cite{CODEBLEU} e \textit{CodeBERTScore}\cite{CODEBERTSCORE}. Estas métricas derivam, respetivamente, de \textit{BLEU}\cite{BLEU} e \textit{BERTScore}\cite{BERTSCORE}, originalmente propostas para tarefas de linguagem natural, tendo sido adaptadas para refletir propriedades sintáticas e semânticas específicas de programas.

\paragraph{CodeBLEU}foi proposta por Ren et al.\cite{CODEBLEU} e constitui uma extensão do \textit{BLEU} tradicional\cite{BLEU}, concebida especificamente para avaliar código gerado automaticamente. Ao contrário do \textit{BLEU} simples, que mede apenas a sobreposição de \textit{n-gramas}, o \textit{CodeBLEU} agrega múltiplas dimensões de análise para refletir propriedades estruturais e semânticas intrínsecas aos programas. A métrica é definida como uma combinação ponderada de quatro componentes distintos:

\begin{equation}
\begin{aligned}
    \text{CodeBLEU} &=
    \alpha \cdot \text{BLEU}
    + \beta \cdot \text{BLEU}_{\text{weighted}} \\
    &\quad
    + \gamma \cdot \text{Match}_{\text{AST}}
    + \delta \cdot \text{Match}_{\text{DF}}.
\end{aligned}
\end{equation}

\noindent{A} componente \textit{BLEU} mantém a métrica original de sobreposição de \textit{n-gramas} entre o código candidato e o código de referência. A componente \(\text{BLEU}_{\text{weighted}}\) introduz um esquema de ponderação que atribui maior peso a palavras-chave da linguagem de programação (por exemplo, \texttt{if}, \texttt{return}, \texttt{class}), refletindo o impacto diferenciado que estes tokens têm na estrutura e funcionamento do programa.

\noindent{Uma} \textit{Abstract Syntax Tree} (AST) constitui a representação estruturada do código, na qual cada nó corresponde a uma construção sintática, como expressões, instruções ou blocos. Estas árvores descrevem a organização hierárquica do programa de forma independente da sua forma textual, permitindo comparar a estrutura sintática entre diferentes fragmentos de código. A componente \(\text{Match}_{\text{AST}}\) explora precisamente esta característica, avaliando a semelhança estrutural entre o candidato e a referência através da correspondência entre as respetivas subárvores, permitindo capturar erros estruturais, como omissões de blocos, incompatibilidades de tipos ou construções sintaticamente incompletas, sendo definida, de forma simplificada, por:
\begin{equation}
\begin{aligned}
\text{Match}_{\text{AST}} 
    &= 
    \frac{\displaystyle \text{total de subárvores coincidentes}}
         {\displaystyle \text{total de subárvores da referência}}
\end{aligned}
\end{equation}

\noindent{Por} sua vez, os grafos de fluxo de dados (\textit{data-flow}) representam a forma como a informação é transmitida e transformada ao longo da execução de um programa, descrevendo as dependências entre variáveis e operações. Estes grafos permitem identificar relações semânticas que não são capturadas apenas pela estrutura sintática, como a origem e propagação de valores ou o modo como diferentes instruções interagem entre si. A componente \(\text{Match}_{\text{DF}}\) recorre precisamente a esta representação para avaliar a similaridade semântica entre o candidato e a referência, comparando os respetivos fluxos de dados associados às variáveis do programa:
\begin{equation}
    \text{Match}_{\text{DF}} =
    \frac{\text{total de fluxos de dados coincidentes}}
         {\text{total de fluxos de dados da referência}}
\end{equation}

Desta forma, é possível distinguir fragmentos de código que são lexicalmente semelhantes, mas que apresentam comportamentos lógicos distintos. Na configuração recomendada pelos autores, os pesos são definidos como \(\alpha = 0.1\), \(\beta = 0.1\), \(\gamma = 0.4\) e \(\delta = 0.4\)\cite{CODEBLEU}, atribuindo maior relevância às componentes sintática e semântica. Os resultados experimentais apresentados no trabalho original evidenciam que o \textit{CodeBLEU} apresenta uma correlação mais elevada com a avaliação humana do que métricas tradicionais baseadas apenas em \textit{BLEU}.

\paragraph{CodeBERTScore}segue a mesma lógica do \textit{BERTScore}\cite{BERTSCORE}, adaptando-o ao domínio da programação através da utilização de modelos de representação de código, como o \textit{CodeBERT}\cite{CODEBERT}. Em vez de se basear apenas na coincidência textual, esta métrica avalia a similaridade entre o código gerado e o código de referência a partir de \textit{embeddings} contextuais, captando relações semânticas que subsistem mesmo quando as duas implementações apresentam diferenças ao nível superficial.

Sejam \(C\) o conjunto de tokens do código candidato e \(R\) o conjunto de tokens da referência e, \(\mathbf{e}_t\), \(\mathbf{e}_r\) os \textit{embeddings} associados a cada token por um modelo pré-treinado. A métrica define valores de \textit{precision} e \textit{recall}, calculando um valor final \text{F1} através da média harmónica entre os dois valores, da seguinte forma:

\begin{equation}
    \text{Precision} =
    \frac{1}{|C|}
    \sum_{t \in C}
    \max_{r \in R}
    \cos\big(\mathbf{e}_t, \mathbf{e}_r\big),
\end{equation}

\begin{equation}
    \text{Recall} =
    \frac{1}{|R|}
    \sum_{r \in R}
    \max_{t \in C}
    \cos\big(\mathbf{e}_r, \mathbf{e}_t\big),
\end{equation}

\begin{equation}
    \text{F1} =
    2 \cdot
    \frac{\text{Precision} \cdot \text{Recall}}
         {\text{Precision} + \text{Recall}}.
\end{equation}

Ao basear-se em representações distribuídas treinadas especificamente em código fonte, o \textit{CodeBERTScore} consegue avaliar a proximidade semântica entre duas soluções, mesmo quando estas utilizam diferentes estruturas de controlo, convenções de nomenclatura ou organizações de código. Esta característica torna a métrica particularmente adequada em cenários em que é expectável a existência de múltiplas implementações corretas para o mesmo problema, complementando assim a avaliação estrutural fornecida pelo \textit{CodeBLEU}\cite{CODEBLEU}.\\

\indent\textbf{Validação humana}

\noindent{Para} além das métricas automáticas, a avaliação da qualidade dos artefactos gerados integra igualmente uma componente de apreciação humana. A análise por parte de um avaliador permite identificar aspetos que não são totalmente captados pelas métricas quantitativas, tais como clareza, adequação ao enunciado, legibilidade e conformidade com boas práticas de programação. A inclusão desta dimensão qualitativa assegura que a comparação entre diferentes combinações de modelos não se limita à proximidade numérica relativamente ao código de referência.

\noindent{Deste} modo, a avaliação final resulta da combinação equilibrada entre métricas automáticas e julgamento humano, garantindo uma análise mais completa e representativa da qualidade global das soluções geradas.

\subsubsection{Refinamento}

O processo de refinamento tem como objetivo melhorar progressivamente a qualidade dos artefactos produzidos pela pipeline, garantindo que estes evoluem de acordo com os requisitos definidos e com as expectativas do utilizador. Este processo assenta em duas componentes complementares, o ciclo de validação humana e a aplicação sistemática de técnicas de \textit{prompt engineering} antes da execução de cada módulo.

\noindent{A} validação humana constitui um mecanismo central deste processo. Após a geração de cada artefacto por parte do respetivo modelo, o resultado é analisado por um avaliador, que determina se este é adequado ou se necessita de ajustamentos. Sempre que o artefacto não cumpre os critérios esperados, o avaliador fornece orientações explícitas que descrevem os aspetos a corrigir. Este feedback é então reintegrado no sistema, originando uma nova iteração de geração. O processo repete-se até que o avaliador considere que o artefacto atinge um nível de qualidade satisfatório. Este ciclo iterativo, ilustrado na Figura \ref{fig:human-validation}, permite incorporar de forma contínua a interpretação humana e assegurar que o sistema se adapta às necessidades específicas do contexto.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{../../img/human_validation.pdf}
    \caption{Ciclo de validação e feedback humano.}
    \label{fig:human-validation}
\end{figure}

\noindent{Para} além da validação humana, o refinamento é reforçado pela aplicação sistemática de técnicas de \textit{prompt engineering} na entrada de cada módulo da pipeline. Estas técnicas orientam o comportamento dos modelos de linguagem, reduzindo ambiguidades e aumentando a precisão, completude e consistência das respostas. A preparação cuidadosa dos pedidos pode incluir a definição de papéis, a formulação estruturada das instruções, a inclusão de exemplos (\textit{few-shot prompting}), a imposição de restrições explícitas ou outras estratégias adequadas ao tipo de artefacto a gerar. Nos diagramas apresentados ao longo desta dissertação, a aplicação destas técnicas é assinalada pelo ícone de duas engrenagens colocado antes de cada modelo, simbolizando que a geração de cada artefacto é antecedida por um conjunto de instruções cuidadosamente formuladas para orientar o comportamento do LLM.

\noindent{A} combinação entre validação humana iterativa e técnicas de \textit{prompt engineering} confere ao processo de refinamento uma natureza adaptativa. Cada iteração incorpora o feedback obtido e melhora o comportamento subsequente dos modelos, promovendo a convergência para artefactos mais completos, precisos e alinhados com o objetivo final da pipeline. Deste modo, o refinamento não apenas complementa a validação automática discutida anteriormente, como assegura um controlo de qualidade dinâmico e sensível ao contexto ao longo de todo o fluxo de geração.

\section{Planeamento do Trabalho}

\noindent{O} trabalho a desenvolver na fase seguinte da dissertação organiza-se em três grandes etapas.\par

\noindent{A} primeira etapa consiste no desenvolvimento do protótipo. Nesta fase será implementada a \textit{pipeline} proposta,  definindo, integrando e articulando os diferentes módulos que serão necessários para a geração de artefactos das diferentes etapas de desenvolvimento de software. Esta fase culminará numa primeira versão funcional da solução.\par

\noindent{Segue-se} uma etapa de avaliação e testes, durante a qual serão analisados os resultados produzidos pela \textit{pipeline}. Serão comparadas diferentes estratégias de prompting e avaliados diversos modelos de linguagem. Esta fase inclui também o refinamento e melhoria da solução sempre que necessário, garantindo maior coerência entre os artefactos gerados e maior robustez no comportamento da pipeline.\par

\noindent{Por} fim, terá lugar a redação e revisão do documento final, que incorpora a consolidação dos resultados obtidos, a descrição detalhada da metodologia seguida e a discussão das limitações e contributos do trabalho.\par

\noindent A Tabela \ref{tableCronograma} apresenta o cronograma das atividades previstas, 
permitindo visualizar a sequência das fases do trabalho e o tempo alocado a cada etapa do projeto.

\begin{table}[H]
\centering
\begin{tabular}{|p{3cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|p{0.5cm}|} 
\hline
\rowcolor{headergray}
\textbf{Descrição das atividades} & \textbf{Jan 26} & \textbf{Fev 26} & \textbf{Mar 26} & \textbf{Abr 26} & \textbf{Mai 26} & \textbf{Jun 26} \\
\hline
\cellcolor{headergray}Desenvolvimento do protótipo & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \cellcolor{ganttblue} & & \\ 
\hline
\cellcolor{headergray}Avaliação e testes & & & & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \\ 
\hline
\cellcolor{headergray}Análise e ajuste do protótipo & & & & & \cellcolor{ganttblue} & \\ 
\hline
\cellcolor{headergray}Redação do documento final & & & & \cellcolor{ganttblue} & \cellcolor{ganttblue} & \cellcolor{ganttblue} \\ 
\hline
\cellcolor{headergray}Revisão final da tese e preparação da defesa & & & & & & \cellcolor{ganttblue} \\ 
\hline
\end{tabular} 
\caption{Cronograma de atividades}
\label{tableCronograma}
\end{table}

%%\section{«Other Section(s) as Appropriate»} \label{sec:work1}

%%The report should include one or more sections providing a detailed description of the problem you are addressing in the project and your plan to tackle it. Use appropriate section titles for what is presented. 

%%You should explain the methods you are planning to use, or have already started to apply, in your project. 

%%This discussion should be grounded in the related work, your own understanding of the problem, and, when available, preliminary results.

%%In case you already have some preliminary results, consider to include a section devoted to them. This section should  describe the work already carried out, what data has already been collected, what analysis and designs have already been done, what methods have been used, what programs and/or preliminary results already exist, etc.

%%\section{Forthcoming Work and Conclusions} \label{sec:conclusions}

%%This section should include subsections describing the work to be carried out during the remainder of the school year and its objectives. 
%
%%It should also present a chronological plan for the completion of the project. 
%
%%Finally, include a concluding subsection that summarizes the contributions already made, provides a preliminary self-assessment of the progress achieved so far, and discusses the main difficulties encountered.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

\end{document}
